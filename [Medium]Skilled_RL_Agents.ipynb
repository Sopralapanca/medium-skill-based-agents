{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0OpfDo6BptY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIS7A-97w03Y",
        "outputId": "75f6dd4b-e180-4731-a030-7ffdca3eb5f9"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Sopralapanca/medium-skill-based-agents.git\n",
        "# %cd /content/medium-skill-based-agents\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UREODkjw6ZL",
        "outputId": "8b81adc0-24b5-468e-dec2-7c9ea6498ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uv 0.9.18 (0cee76417 2025-12-16)\n"
          ]
        }
      ],
      "source": [
        "!uv --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T3VGFLkD12DN"
      },
      "outputs": [],
      "source": [
        "# ! yes | pip uninstall gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkFEB459xstf",
        "outputId": "edd35456-4996-4e49-d40b-15ded54316df"
      },
      "outputs": [],
      "source": [
        "# !uv pip install -r pyproject.toml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ-Fqi6A2H5t",
        "outputId": "6b330c80-6639-4dab-f134-9d64cb8ae19b"
      },
      "outputs": [],
      "source": [
        "# !python create_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python train_vos.py\n",
        "# !python train_vok.py\n",
        "# !python train_usr.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the required packages, build the environment and test if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# general imports\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# training imports\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# IMPORTANT - REGISTER THE ENVIRONMENTS\n",
        "import gymnasium as gym\n",
        "import ale_py \n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# Load config\n",
        "_config_path = \"./configs.yaml\"\n",
        "\n",
        "_config = {}\n",
        "with open(_config_path, \"r\") as f:\n",
        "    _config = yaml.safe_load(f) or {}\n",
        "        \n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # ignore tensorflow warnings about CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "seed = None\n",
        "if seed is not None:    \n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "#envs = _config.get(\"ENVS\", [\"PongNoFrameskip-v4\"])[0]\n",
        "env = \"PongNoFrameskip-v4\"\n",
        "with open(f'environment_configs/{env}.yaml', 'r') as file:\n",
        "        environment_configuration = yaml.safe_load(file)[\"config\"]\n",
        "\n",
        "\n",
        "environment_configuration[\"f_ext_kwargs\"][\"device\"] = device  #do not comment this, it is the parameter passed to the feature extractor\n",
        "environment_configuration[\"game\"] = env\n",
        "\n",
        "\n",
        "\n",
        "vec_envs = make_atari_env(env, n_envs=environment_configuration[\"n_envs\"], seed=seed)\n",
        "vec_envs = VecFrameStack(vec_envs, n_stack=environment_configuration[\"n_stacks\"])\n",
        "vec_envs = VecTransposeImage(vec_envs)\n",
        "\n",
        "# execute some steps with random moves\n",
        "obs = vec_envs.reset()\n",
        "\n",
        "for i in range(10):\n",
        "    action = [vec_envs.action_space.sample() for _ in range(environment_configuration[\"n_envs\"])]\n",
        "    obs, rewards, dones, info = vec_envs.step(action)\n",
        "\n",
        "# obs[0] has shape (4, 84, 84) because there are 4 stacked environments, take the first\n",
        "observation = obs[0][-1]\n",
        "plt.imshow(observation)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 84, 84)\n",
            "\n",
            "Testing skill input adapters:\n",
            "\n",
            "Skill: state_rep_uns\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 160, 210])\n",
            "\n",
            "Skill: obj_key_enc\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: obj_key_key\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: vid_obj_seg\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 2, 84, 84])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4319.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "from skills.autoencoder import Autoencoder\n",
        "from skills.unsupervised_state_representation import UnsupervisedStateRepresentationModel\n",
        "from skills.video_object_keypoints import Transporter\n",
        "from skills.video_object_segmentation import VideoObjectSegmentationModel\n",
        "from utils.feature_extractors import WeightSharingAttentionExtractor\n",
        "\n",
        "# init skills\n",
        "autoencoder = Autoencoder(channels=1).to(device)\n",
        "\n",
        "# observation has shape (32, 4, 84, 84), \n",
        "# observation = obs[0][0][None, :, :] # (1, 84, 84)\n",
        "\n",
        "print(obs[0].shape) # (4, 84, 84)\n",
        "\n",
        "\n",
        "usr = UnsupervisedStateRepresentationModel(observation=obs[0], device=device)\n",
        "vok = Transporter().to(device)\n",
        "vos = VideoObjectSegmentationModel(device=device)\n",
        "\n",
        "\n",
        "skills = [\n",
        "    usr.get_skill(device=device),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"encoder\"),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"keynet\"),\n",
        "    vos.get_skill(device=device)\n",
        "]\n",
        "\n",
        "# Test each skill's input adapter\n",
        "print(\"\\nTesting skill input adapters:\")\n",
        "test_obs = obs[:1]  # Take one sample from batch\n",
        "test_obs = torch.tensor(test_obs, dtype=torch.float32).to(device)\n",
        "\n",
        "for skill in skills:\n",
        "    print(f\"\\nSkill: {skill.name}\")\n",
        "    print(f\"Input shape: {test_obs.shape}\")\n",
        "    adapted = skill.input_adapter(test_obs)\n",
        "    print(f\"After adapter: {adapted.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "ename": "InductorError",
          "evalue": "RuntimeError: Compiler: cl is not found.\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mInductorError\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     14\u001b[39m policy_kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     15\u001b[39m     features_extractor_class=environment_configuration[\u001b[33m\"\u001b[39m\u001b[33mf_ext_class\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     16\u001b[39m     features_extractor_kwargs=f_ext_kwargs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# activation_fn=th.nn.ReLU,  # use ReLU in case of multiple layers for the policy learning network\u001b[39;00m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m logdir = \u001b[33m\"\u001b[39m\u001b[33m./tensorboard_logs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m model = \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCnnPolicy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvec_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinear_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclip_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinear_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclip_range\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_advantage\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnormalize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ment_coef\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvf_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvf_coef\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:171\u001b[39m, in \u001b[36mPPO.__init__\u001b[39m\u001b[34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28mself\u001b[39m.target_kl = target_kl\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:174\u001b[39m, in \u001b[36mPPO._setup_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;66;03m# Initialize schedules for policy/value clipping\u001b[39;00m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m.clip_range = FloatSchedule(\u001b[38;5;28mself\u001b[39m.clip_range)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:135\u001b[39m, in \u001b[36mOnPolicyAlgorithm._setup_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28mself\u001b[39m.rollout_buffer_class = RolloutBuffer\n\u001b[32m    125\u001b[39m \u001b[38;5;28mself\u001b[39m.rollout_buffer = \u001b[38;5;28mself\u001b[39m.rollout_buffer_class(\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_steps,\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m.observation_space,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    133\u001b[39m     **\u001b[38;5;28mself\u001b[39m.rollout_buffer_kwargs,\n\u001b[32m    134\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28mself\u001b[39m.policy = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28mself\u001b[39m.policy = \u001b[38;5;28mself\u001b[39m.policy.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Warn when not using CPU with MlpPolicy\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:818\u001b[39m, in \u001b[36mActorCriticCnnPolicy.__init__\u001b[39m\u001b[34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[39m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    799\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    800\u001b[39m     observation_space: spaces.Space,\n\u001b[32m   (...)\u001b[39m\u001b[32m    816\u001b[39m     optimizer_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    817\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mortho_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_std_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_expln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43msquash_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshare_features_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:507\u001b[39m, in \u001b[36mActorCriticPolicy.__init__\u001b[39m\u001b[34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28mself\u001b[39m.ortho_init = ortho_init\n\u001b[32m    506\u001b[39m \u001b[38;5;28mself\u001b[39m.share_features_extractor = share_features_extractor\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[38;5;28mself\u001b[39m.features_extractor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.features_dim = \u001b[38;5;28mself\u001b[39m.features_extractor.features_dim\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.share_features_extractor:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:120\u001b[39m, in \u001b[36mBaseModel.make_features_extractor\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_features_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> BaseFeaturesExtractor:\n\u001b[32m    119\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Helper method to create a features extractor.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\utils\\feature_extractors.py:116\u001b[39m, in \u001b[36mWeightSharingAttentionExtractor.__init__\u001b[39m\u001b[34m(self, observation_space, features_dim, skills, device)\u001b[39m\n\u001b[32m    112\u001b[39m sample = sample.to(device)\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m#dropout_p = 0.1\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# this will populate self.skills_embeddings\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# linear layers to learn a representation of the skills\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.mlp_layers = nn.ModuleList()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\utils\\feature_extractors.py:74\u001b[39m, in \u001b[36mFeaturesExtractor.preprocess_input\u001b[39m\u001b[34m(self, observations)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     73\u001b[39m     so = skill.input_adapter(observations)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     so = \u001b[43mskill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskill_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskill_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mso\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# can return linear or spatial embeddings\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skill.name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.adapters:\n\u001b[32m     77\u001b[39m     adapter = \u001b[38;5;28mself\u001b[39m.adapters[skill.name]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\skills\\skill_interface.py:10\u001b[39m, in \u001b[36mmodel_forward\u001b[39m\u001b[34m(model, x)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_forward\u001b[39m(model, x):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Default forward wrapper for skill models.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:414\u001b[39m, in \u001b[36mOptimizedModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.nn.modules.module._has_any_global_hook():\n\u001b[32m    405\u001b[39m     warnings.warn(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing `torch.compile(module)` when there are global hooks on \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodules (e.g., from `register_module_forward_hook`); this will\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    412\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    413\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:845\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    841\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__cause__\u001b[39;00m  \u001b[38;5;66;03m# User compiler error\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ShortenTraceback \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    843\u001b[39m     \u001b[38;5;66;03m# Failures in the backend likely don't have useful\u001b[39;00m\n\u001b[32m    844\u001b[39m     \u001b[38;5;66;03m# data in the TorchDynamo frames, so we strip them out.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.remove_dynamo_frames() \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# see TORCHDYNAMO_VERBOSE=1\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    847\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    848\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:990\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **graph_kwargs)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InductorError(e, currentframe()).with_traceback(\n\u001b[32m    991\u001b[39m         e.__traceback__\n\u001b[32m    992\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    994\u001b[39m     TritonBundler.end_compile()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:974\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **graph_kwargs)\u001b[39m\n\u001b[32m    972\u001b[39m TritonBundler.begin_compile()\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     mb_compiled_graph = \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    978\u001b[39m     mb_compiled_graph._time_taken_ns = time.time_ns() - start_time\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1695\u001b[39m, in \u001b[36mfx_codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[39m\n\u001b[32m   1691\u001b[39m     fast_scheme = _InProcessFxCompile()\n\u001b[32m   1693\u001b[39m     scheme = _ProgressiveFxCompile(fast_scheme, scheme, progression_configs)\n\u001b[32m-> \u001b[39m\u001b[32m1695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1505\u001b[39m, in \u001b[36m_InProcessFxCompile.codegen_and_compile\u001b[39m\u001b[34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[39m\n\u001b[32m   1487\u001b[39m         compiled_fn = AotCodeCompiler.compile(\n\u001b[32m   1488\u001b[39m             graph,\n\u001b[32m   1489\u001b[39m             wrapper_code.value,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1502\u001b[39m             ],\n\u001b[32m   1503\u001b[39m         )\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m     compiled_module = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m     compiled_fn = compiled_module.call\n\u001b[32m   1507\u001b[39m     compiled_fn_runner = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   1508\u001b[39m         compiled_module, \u001b[33m\"\u001b[39m\u001b[33mrunner\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1509\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:2319\u001b[39m, in \u001b[36mGraphLowering.compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> CompiledModule:\n\u001b[32m   2313\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   2314\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraphLowering.compile_to_module\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2315\u001b[39m         phase_name=\u001b[33m\"\u001b[39m\u001b[33mcode_gen\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2316\u001b[39m         log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2317\u001b[39m         dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33minductor_code_gen_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2318\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m2319\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:2325\u001b[39m, in \u001b[36mGraphLowering._compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> CompiledModule:\n\u001b[32m   2322\u001b[39m     \u001b[38;5;66;03m# If we're here, we don't have to worry about the kernel code, which is only\u001b[39;00m\n\u001b[32m   2323\u001b[39m     \u001b[38;5;66;03m# returned separately in AOTInductor mode.\u001b[39;00m\n\u001b[32m   2324\u001b[39m     wrapper_code, _ = (\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m         \u001b[38;5;28mself\u001b[39m.codegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2326\u001b[39m     )\n\u001b[32m   2328\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(wrapper_code, ValueWithLineMap):\n\u001b[32m   2329\u001b[39m         mod = \u001b[38;5;28mself\u001b[39m._compile_to_module_lines(wrapper_code)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:2264\u001b[39m, in \u001b[36mGraphLowering.codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2261\u001b[39m V.debug.draw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m.orig_gm, \u001b[38;5;28mself\u001b[39m.scheduler.nodes)\n\u001b[32m   2263\u001b[39m \u001b[38;5;28mself\u001b[39m.wrapper_code.push_codegened_graph(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2264\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2266\u001b[39m log.debug(\n\u001b[32m   2267\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished codegen for all nodes. The list of kernel names available: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   2268\u001b[39m     V.graph.all_codegen_kernel_names,\n\u001b[32m   2269\u001b[39m )\n\u001b[32m   2271\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrapper_code.generate(\u001b[38;5;28mself\u001b[39m.is_inference)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:5197\u001b[39m, in \u001b[36mScheduler.codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   5194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcodegen\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5195\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mScheduler.codegen\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   5196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m5197\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_codegen_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5198\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m torch._inductor.config.graph_partition\n\u001b[32m   5199\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._codegen(\u001b[38;5;28mself\u001b[39m.nodes)\n\u001b[32m   5200\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:5337\u001b[39m, in \u001b[36mScheduler._codegen_partitions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   5332\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(partition) >= \u001b[32m1\u001b[39m, (\n\u001b[32m   5333\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEach partition must have at least one node but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(partition)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   5334\u001b[39m )\n\u001b[32m   5336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m signature.skip_cudagraph:\n\u001b[32m-> \u001b[39m\u001b[32m5337\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_codegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5339\u001b[39m     \u001b[38;5;28mself\u001b[39m._codegen_partition_wrapper(partition, signature)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:5435\u001b[39m, in \u001b[36mScheduler._codegen\u001b[39m\u001b[34m(self, nodes)\u001b[39m\n\u001b[32m   5433\u001b[39m     backend.codegen_combo_kernel(node)\n\u001b[32m   5434\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (FusedSchedulerNode, SchedulerNode)):\n\u001b[32m-> \u001b[39m\u001b[32m5435\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5436\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5437\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, NopKernelSchedulerNode)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py:5282\u001b[39m, in \u001b[36mCppScheduling.codegen_node\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   5280\u001b[39m nodes: \u001b[38;5;28mlist\u001b[39m[SchedulerNode] = node.get_nodes()  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   5281\u001b[39m nodes = \u001b[38;5;28mself\u001b[39m.try_loop_split(nodes)\n\u001b[32m-> \u001b[39m\u001b[32m5282\u001b[39m cpp_kernel_proxy = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_proxy_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5283\u001b[39m cpp_kernel_proxy.codegen_nodes(nodes)\n\u001b[32m   5284\u001b[39m kernel_group.finalize_kernel(cpp_kernel_proxy, nodes)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py:4008\u001b[39m, in \u001b[36mCppKernelProxy.__init__\u001b[39m\u001b[34m(self, kernel_group)\u001b[39m\n\u001b[32m   4006\u001b[39m \u001b[38;5;28mself\u001b[39m.loop_nest = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4007\u001b[39m \u001b[38;5;28mself\u001b[39m.call_ranges = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4008\u001b[39m \u001b[38;5;28mself\u001b[39m.picked_vec_isa: cpu_vec_isa.VecISA = \u001b[43mcpu_vec_isa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpick_vec_isa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4009\u001b[39m \u001b[38;5;28mself\u001b[39m.kernels: \u001b[38;5;28mlist\u001b[39m[CppKernel] = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:497\u001b[39m, in \u001b[36mpick_vec_isa\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode() \u001b[38;5;129;01mand\u001b[39;00m (platform.machine() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mx86_64\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAMD64\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m VecAVX2()\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m _valid_vec_isa_list: \u001b[38;5;28mlist\u001b[39m[VecISA] = \u001b[43mvalid_vec_isa_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _valid_vec_isa_list:\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_vec_isa\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:484\u001b[39m, in \u001b[36mvalid_vec_isa_list\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     \u001b[43misa_list\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msupported_vec_isa_list\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_cpu_supported_x86_isa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43misa\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43misa\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:487\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[33;03m    arch value is x86_64 on Linux, and the value is AMD64 on Windows.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m     _cpu_supported_x86_isa = x86_isa_checker()\n\u001b[32m    484\u001b[39m     isa_list.extend(\n\u001b[32m    485\u001b[39m         isa\n\u001b[32m    486\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m isa \u001b[38;5;129;01min\u001b[39;00m supported_vec_isa_list\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(flag \u001b[38;5;129;01min\u001b[39;00m _cpu_supported_x86_isa \u001b[38;5;28;01mfor\u001b[39;00m flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(isa).split()) \u001b[38;5;129;01mand\u001b[39;00m isa\n\u001b[32m    488\u001b[39m     )\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m isa_list\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:143\u001b[39m, in \u001b[36mVecISA.__bool__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__bool__impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvec_isa_ok\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:153\u001b[39m, in \u001b[36mVecISA.__bool__impl\u001b[39m\u001b[34m(self, vec_isa_ok)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.is_fbcode():\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVecISA\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_avx_code\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:103\u001b[39m, in \u001b[36mVecISA.check_build\u001b[39m\u001b[34m(self, code)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodecache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lock_dir, LOCK_TIMEOUT, write\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     CppBuilder,\n\u001b[32m     96\u001b[39m     CppTorchOptions,\n\u001b[32m     97\u001b[39m     normalize_path_separator,\n\u001b[32m     98\u001b[39m )\n\u001b[32m    100\u001b[39m key, input_path = write(\n\u001b[32m    101\u001b[39m     code,\n\u001b[32m    102\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcpp\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     extra=\u001b[43m_get_isa_dry_compile_fingerprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arch_flags\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    104\u001b[39m )\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[32m    107\u001b[39m lock_dir = get_lock_dir()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py:29\u001b[39m, in \u001b[36m_get_isa_dry_compile_fingerprint\u001b[39m\u001b[34m(isa_flags)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_isa_dry_compile_fingerprint\u001b[39m(isa_flags: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# ISA dry compile will cost about 1 sec time each startup time.\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Please check the issue: https://github.com/pytorch/pytorch/issues/100378\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# and generated them to output binary hash path.\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# It would optimize and skip compile existing binary.\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compiler_version_info, get_cpp_compiler\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     compiler_info = get_compiler_version_info(\u001b[43mget_cpp_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     30\u001b[39m     torch_version = torch.__version__\n\u001b[32m     31\u001b[39m     fingerprint = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00misa_flags\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:338\u001b[39m, in \u001b[36mget_cpp_compiler\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    336\u001b[39m     compiler = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCXX\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    337\u001b[39m     compiler = normalize_path_separator(compiler)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[43mcheck_compiler_exist_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     check_msvc_cl_language_id(compiler)\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py:139\u001b[39m, in \u001b[36mcheck_compiler_exist_windows\u001b[39m\u001b[34m(compiler)\u001b[39m\n\u001b[32m    137\u001b[39m     subprocess.check_output([compiler, \u001b[33m\"\u001b[39m\u001b[33m/help\u001b[39m\u001b[33m\"\u001b[39m], stderr=subprocess.STDOUT)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompiler: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompiler\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not found.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.SubprocessError:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# Expected that some compiler(clang, clang++) is exist, but they not support `/help` args.\u001b[39;00m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "\u001b[31mInductorError\u001b[39m: RuntimeError: Compiler: cl is not found.\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from rl_zoo3.utils import linear_schedule\n",
        "\n",
        "\n",
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "\n",
        "environment_configuration[\"f_ext_name\"] = \"wsharing_attention_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = WeightSharingAttentionExtractor\n",
        "\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=environment_configuration[\"f_ext_class\"],\n",
        "    features_extractor_kwargs=f_ext_kwargs,\n",
        "    net_arch={\n",
        "        \"pi\": environment_configuration[\"net_arch_pi\"],\n",
        "        \"vf\": environment_configuration[\"net_arch_vf\"],\n",
        "    },\n",
        "    # activation_fn=th.nn.ReLU,  # use ReLU in case of multiple layers for the policy learning network\n",
        ")\n",
        "\n",
        "logdir = \"./tensorboard_logs\"\n",
        "\n",
        "model = PPO(\n",
        "    \"CnnPolicy\",\n",
        "    vec_envs,\n",
        "    learning_rate=linear_schedule(environment_configuration[\"learning_rate\"]),\n",
        "    n_steps=128,\n",
        "    n_epochs=4,\n",
        "    batch_size=environment_configuration[\"batch_size\"],\n",
        "    clip_range=linear_schedule(environment_configuration[\"clip_range\"]),\n",
        "    normalize_advantage=environment_configuration[\"normalize\"],\n",
        "    ent_coef=environment_configuration[\"ent_coef\"],\n",
        "    vf_coef=environment_configuration[\"vf_coef\"],\n",
        "    policy_kwargs=policy_kwargs,\n",
        "    verbose=1,\n",
        "    device=device,\n",
        "    tensorboard_log=logdir,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to ./tensorboard_logs\\test_run_1_wsa_2\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 60   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 16   |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     12\u001b[39m eval_callback = EvalCallback(\n\u001b[32m     13\u001b[39m     eval_env,\n\u001b[32m     14\u001b[39m     n_eval_episodes=\u001b[32m100\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     verbose=\u001b[32m0\u001b[39m,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m callbacks = [eval_callback]\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[39m, in \u001b[36mPPO.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[32m    304\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    310\u001b[39m ) -> SelfPPO:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:337\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    334\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28mself\u001b[39m.dump_logs(iteration)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m callback.on_training_end()\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:213\u001b[39m, in \u001b[36mPPO.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_space, spaces.Discrete):\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m# Convert discrete action from float to long\u001b[39;00m\n\u001b[32m    211\u001b[39m     actions = rollout_data.actions.long().flatten()\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m values, log_prob, entropy = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m values = values.flatten()\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:730\u001b[39m, in \u001b[36mActorCriticPolicy.evaluate_actions\u001b[39m\u001b[34m(self, obs, actions)\u001b[39m\n\u001b[32m    720\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[33;03mEvaluate actions according to the current policy,\u001b[39;00m\n\u001b[32m    722\u001b[39m \u001b[33;03mgiven the observations.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    727\u001b[39m \u001b[33;03m    and entropy of the action distribution.\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m730\u001b[39m features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.share_features_extractor:\n\u001b[32m    732\u001b[39m     latent_pi, latent_vf = \u001b[38;5;28mself\u001b[39m.mlp_extractor(features)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:672\u001b[39m, in \u001b[36mActorCriticPolicy.extract_features\u001b[39m\u001b[34m(self, obs, features_extractor)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    664\u001b[39m \u001b[33;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[32m    665\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    669\u001b[39m \u001b[33;03m    features for the actor and the features for the critic.\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.share_features_extractor:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    674\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:131\u001b[39m, in \u001b[36mBaseModel.extract_features\u001b[39m\u001b[34m(self, obs, features_extractor)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[32m    125\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m \u001b[33;03m:return: The extracted features\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m preprocessed_obs = preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m.observation_space, normalize_images=\u001b[38;5;28mself\u001b[39m.normalize_images)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\utils\\feature_extractors.py:177\u001b[39m, in \u001b[36mWeightSharingAttentionExtractor.forward\u001b[39m\u001b[34m(self, observations)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations: torch.Tensor) -> torch.Tensor:\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m#print(\"forward observation shape\", observations.shape)\u001b[39;00m\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# -------------- saving stats -------------- #\u001b[39;00m\n\u001b[32m    175\u001b[39m     weights = []\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# this will populate self.skills_embeddings\u001b[39;00m\n\u001b[32m    179\u001b[39m     encoded_frame = \u001b[38;5;28mself\u001b[39m.get_last_frame_embedding_for_context(observations)\n\u001b[32m    180\u001b[39m     encoded_frame = \u001b[38;5;28mself\u001b[39m.encoder_lin_layer(encoded_frame)  \u001b[38;5;66;03m# query\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\utils\\feature_extractors.py:74\u001b[39m, in \u001b[36mFeaturesExtractor.preprocess_input\u001b[39m\u001b[34m(self, observations)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     73\u001b[39m     so = skill.input_adapter(observations)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     so = \u001b[43mskill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskill_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskill_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mso\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# can return linear or spatial embeddings\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skill.name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.adapters:\n\u001b[32m     77\u001b[39m     adapter = \u001b[38;5;28mself\u001b[39m.adapters[skill.name]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\skills\\video_object_segmentation.py:269\u001b[39m, in \u001b[36mVideoObjectSegmentationModel.vos_output_masks\u001b[39m\u001b[34m(self, model, x)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvos_output_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, x):\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\skills\\video_object_segmentation.py:78\u001b[39m, in \u001b[36mVideoObjectSegmentationModel.compute_masks\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# [ BS x K x H x W ]\u001b[39;00m\n\u001b[32m     77\u001b[39m m = \u001b[38;5;28mself\u001b[39m.conv_m3(m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m m = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:359\u001b[39m, in \u001b[36mSigmoid.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    356\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
        "\n",
        "\n",
        "eval_env = make_atari_env(env, n_envs=environment_configuration[\"n_envs\"])\n",
        "eval_env = VecFrameStack(eval_env, n_stack=environment_configuration[\"n_stacks\"])\n",
        "eval_env = VecTransposeImage(eval_env)\n",
        "\n",
        "run_id = \"test_run_1_wsa\"\n",
        "eval_logs = f\"eval_logs/{env}/{run_id}\"\n",
        "os.makedirs(eval_logs, exist_ok=True)\n",
        "\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    n_eval_episodes=100,\n",
        "    best_model_save_path=f\"./agents/{run_id}\",\n",
        "    log_path=eval_logs,\n",
        "    eval_freq=5000 * environment_configuration[\"n_envs\"],\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "callbacks = [eval_callback]\n",
        "\n",
        "model.learn(10000, callback=callbacks, tb_log_name=run_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMtMYo6f1slK1K86xPI/xkL",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "skill-based-agents (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
