{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0OpfDo6BptY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIS7A-97w03Y",
        "outputId": "57a0547e-26a8-471d-a917-332aa8868d9c"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Sopralapanca/medium-skill-based-agents.git\n",
        "# %cd /content/medium-skill-based-agents\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkFEB459xstf",
        "outputId": "9b872278-6cb9-4c2c-96b8-80d8d98e25bf"
      },
      "outputs": [],
      "source": [
        "# !uv pip install -r pyproject.toml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HQ-Fqi6A2H5t"
      },
      "outputs": [],
      "source": [
        "# !python create_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1PiyVRcgMUdK"
      },
      "outputs": [],
      "source": [
        "# !python train_vos.py\n",
        "# !python train_vok.py\n",
        "# !python train_usr.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_C88ROwMUdL"
      },
      "source": [
        "Import the required packages, build the environment and test if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1xZN1JaoBj4",
        "outputId": "19907a38-ba08-464a-9825-9b18e54c4154"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-27 10:50:29.412461: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/home/giacomo/Documents/code-projects/medium-skill-based-agents/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        }
      ],
      "source": [
        "# general imports\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# training imports\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# IMPORTANT - REGISTER THE ENVIRONMENTS\n",
        "import gymnasium as gym\n",
        "import ale_py\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# Load config\n",
        "_config_path = \"./configs.yaml\"\n",
        "\n",
        "_config = {}\n",
        "with open(_config_path, \"r\") as f:\n",
        "    _config = yaml.safe_load(f) or {}\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # ignore tensorflow warnings about CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "seed = None\n",
        "if seed is not None:\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "#envs = _config.get(\"ENVS\", [\"PongNoFrameskip-v4\"])[0]\n",
        "env = \"PongNoFrameskip-v4\"\n",
        "with open(f'environment_configs/{env}.yaml', 'r') as file:\n",
        "        environment_configuration = yaml.safe_load(file)[\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_env(env_id, configs, seed=None):\n",
        "    env = make_atari_env(env_id, n_envs=configs[\"n_envs\"], seed=seed)\n",
        "    env = VecFrameStack(env, n_stack=configs[\"n_stacks\"])\n",
        "    env = VecTransposeImage(env)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KjcYdvrRWjXI"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "key = os.getenv(\"WANDB_API_KEY\")\n",
        "if key is None:\n",
        "    raise ValueError(\"WANDB_API_KEY not set\")\n",
        "\n",
        "def init_wandb(environment_configuration):\n",
        "  wandb.login(key=key)\n",
        "\n",
        "  tags = [\n",
        "      f\"fe:{environment_configuration['f_ext_name']}\",\n",
        "      f\"game:{environment_configuration['game']}\",\n",
        "  ]\n",
        "\n",
        "  run = wandb.init(\n",
        "      project=\"medium-skill-based-agents\",\n",
        "      config=environment_configuration,\n",
        "      sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "      monitor_gym=False,  # auto-upload the videos of agents playing the game\n",
        "      group=f\"{environment_configuration['game']}\",\n",
        "      tags=tags\n",
        "      # save_code = True,  # optional\n",
        "  )\n",
        "\n",
        "  return run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "wolJs-iNMUdL",
        "outputId": "380143db-de7f-4eb8-d65b-23f0f6b49e2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_envs = create_env(env_id=env, configs=environment_configuration, seed=seed)\n",
        "\n",
        "# execute some steps with random moves\n",
        "obs = test_envs.reset()\n",
        "\n",
        "for i in range(10):\n",
        "    action = [test_envs.action_space.sample() for _ in range(environment_configuration[\"n_envs\"])]\n",
        "    obs, rewards, dones, info = test_envs.step(action)\n",
        "\n",
        "# obs[0] has shape (4, 84, 84) because there are 4 stacked environments, take the first\n",
        "observation = obs[0][-1]\n",
        "plt.imshow(observation)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility function for training agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from stable_baselines3 import PPO\n",
        "from rl_zoo3.utils import linear_schedule\n",
        "from utils.monitor_moe_weights import GatingMonitorCallback\n",
        "from utils.feature_extractors import MixtureOfExpertsExtractor\n",
        "\n",
        "\n",
        "\n",
        "def train_agent(env_id, configs, policy_kwargs, seed):\n",
        "    \n",
        "    #run = init_wandb(configs)\n",
        "    logdir = \"./tensorboard_logs\"\n",
        "    \n",
        "    # monitor_dir = str(run.id)\n",
        "    monitor_dir = \"ppo\"\n",
        "\n",
        "    vec_envs = create_env(env_id=env_id, configs=configs, seed=seed)\n",
        "    _ = vec_envs.reset()\n",
        "    \n",
        "    eval_envs = create_env(env_id=env_id, configs=configs, seed=None)\n",
        "\n",
        "    model = PPO(\n",
        "        \"CnnPolicy\",\n",
        "        vec_envs,\n",
        "        learning_rate=linear_schedule(environment_configuration[\"learning_rate\"]),\n",
        "        n_steps=environment_configuration[\"n_steps\"],\n",
        "        n_epochs=environment_configuration[\"n_epochs\"],\n",
        "        batch_size=environment_configuration[\"batch_size\"],\n",
        "        clip_range=linear_schedule(environment_configuration[\"clip_range\"]),\n",
        "        normalize_advantage=environment_configuration[\"normalize\"],\n",
        "        ent_coef=environment_configuration[\"ent_coef\"],\n",
        "        vf_coef=environment_configuration[\"vf_coef\"],\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        verbose=1,\n",
        "        device=device,\n",
        "        tensorboard_log=logdir,\n",
        "    )\n",
        "\n",
        "\n",
        "    eval_logs = f\"eval_logs/{env}/{monitor_dir}\"\n",
        "    os.makedirs(eval_logs, exist_ok=True)\n",
        "\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_envs,\n",
        "        n_eval_episodes=100,\n",
        "        best_model_save_path=f\"./agents/{monitor_dir}\",\n",
        "        log_path=eval_logs,\n",
        "        eval_freq=5000 * environment_configuration[\"n_envs\"],\n",
        "        verbose=0,\n",
        "    )\n",
        "    \n",
        "    \n",
        "    callbacks = [\n",
        "        #WandbCallback(verbose=0),\n",
        "        eval_callback\n",
        "    ]\n",
        "\n",
        "    if configs[\"f_ext_name\"] == \"moe_ext\":\n",
        "        print(\"ci sono\")\n",
        "        # Get the feature extractor from the model\n",
        "        feature_extractor = model.policy.features_extractor\n",
        "\n",
        "        # Create monitoring callback\n",
        "        gating_monitor = GatingMonitorCallback(\n",
        "            feature_extractor=feature_extractor,\n",
        "            env=env_id,\n",
        "            save_freq=500,  # Save every 500 steps\n",
        "            save_path=\"./gating_weights\",\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        callbacks.append(gating_monitor)\n",
        "        \n",
        "    model.learn(5000, callback=callbacks, progress_bar=True) #tb_log_name=run.id)\n",
        "    #run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch={\n",
        "        \"pi\": environment_configuration[\"net_arch_pi\"],\n",
        "        \"vf\": environment_configuration[\"net_arch_vf\"],\n",
        "    },\n",
        "    # activation_fn=torch.nn.ReLU,  # use ReLU in case of multiple layers for the policy learning network\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Standard PPO Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Skills initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_98s5PWMUdM",
        "outputId": "45789a98-3844-47b1-82fa-e3664cde07d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 84, 84)\n",
            "\n",
            "Testing skill input adapters:\n",
            "\n",
            "Skill: state_rep_uns\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 160, 210])\n",
            "\n",
            "Skill: obj_key_enc\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: obj_key_key\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: vid_obj_seg\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 2, 84, 84])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/giacomo/Documents/code-projects/medium-skill-based-agents/.venv/lib/python3.12/site-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "from skills.autoencoder import Autoencoder\n",
        "from skills.unsupervised_state_representation import UnsupervisedStateRepresentationModel\n",
        "from skills.video_object_keypoints import Transporter\n",
        "from skills.video_object_segmentation import VideoObjectSegmentationModel\n",
        "\n",
        "# init skills\n",
        "autoencoder = Autoencoder(channels=1).to(device)\n",
        "\n",
        "# observation has shape (32, 4, 84, 84),\n",
        "# observation = obs[0][0][None, :, :] # (1, 84, 84)\n",
        "\n",
        "print(obs[0].shape) # (4, 84, 84)\n",
        "\n",
        "environment_configuration[\"f_ext_kwargs\"][\"device\"] = device  #do not comment this, it is the parameter passed to the feature extractor\n",
        "environment_configuration[\"game\"] = env\n",
        "\n",
        "\n",
        "usr = UnsupervisedStateRepresentationModel(observation=obs[0], device=device)\n",
        "vok = Transporter().to(device)\n",
        "vos = VideoObjectSegmentationModel(device=device)\n",
        "\n",
        "\n",
        "skills = [\n",
        "    usr.get_skill(device=device),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"encoder\"),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"keynet\"),\n",
        "    vos.get_skill(device=device)\n",
        "]\n",
        "\n",
        "# Test each skill's input adapter\n",
        "print(\"\\nTesting skill input adapters:\")\n",
        "test_obs = obs[:1]  # Take one sample from batch\n",
        "test_obs = torch.tensor(test_obs, dtype=torch.float32).to(device)\n",
        "\n",
        "for skill in skills:\n",
        "    print(f\"\\nSkill: {skill.name}\")\n",
        "    print(f\"Input shape: {test_obs.shape}\")\n",
        "    adapted = skill.input_adapter(test_obs)\n",
        "    print(f\"After adapter: {adapted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train WSA agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from utils.feature_extractors import WeightSharingAttentionExtractor\n",
        "\n",
        "# f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "# environment_configuration[\"f_ext_name\"] = \"wsharing_attention_ext\"\n",
        "# environment_configuration[\"f_ext_class\"] = WeightSharingAttentionExtractor\n",
        "# f_ext_kwargs[\"skills\"] = skills\n",
        "# f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "# policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "# policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "# train_agent(env, environment_configuration, policy_kwargs, seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train MOE agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "ci sono\n",
            "Logging to ./tensorboard_logs/PPO_21\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5c289b099a74a3e85b2e38cd5211b98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 83   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 12   |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 18           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 111          |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015067689 |\n",
            "|    clip_fraction        | 0.0923       |\n",
            "|    clip_range           | 0.0795       |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -0.0685      |\n",
            "|    learning_rate        | 0.000199     |\n",
            "|    loss                 | 0.0647       |\n",
            "|    n_updates            | 4            |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    value_loss           | 0.47         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 15            |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 203           |\n",
            "|    total_timesteps      | 3072          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00051335647 |\n",
            "|    clip_fraction        | 0.053         |\n",
            "|    clip_range           | 0.059         |\n",
            "|    entropy_loss         | -1.79         |\n",
            "|    explained_variance   | 9.13e-05      |\n",
            "|    learning_rate        | 0.000148      |\n",
            "|    loss                 | 0.0493        |\n",
            "|    n_updates            | 8             |\n",
            "|    policy_gradient_loss | -0.00128      |\n",
            "|    value_loss           | 0.148         |\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from utils.feature_extractors import MixtureOfExpertsExtractor\n",
        "\n",
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "environment_configuration[\"f_ext_name\"] = \"moe_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = MixtureOfExpertsExtractor\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.monitor_moe_weights import plot_gating_distribution\n",
        "\n",
        "# Plot the results\n",
        "weights_file = f\"./gating_weights/gating_weights_{env}.pkl\"\n",
        "if os.path.exists(weights_file):\n",
        "    plot_gating_distribution(weights_file, output_dir=\"./gating_plots\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Warning: Weights file not found at {weights_file}\")\n",
        "    \n",
        "# Load and visualize gating weights from a saved file\n",
        "weights_file = f\"./gating_weights/gating_weights_{env}.pkl\"\n",
        "\n",
        "if os.path.exists(weights_file):\n",
        "    data = plot_gating_distribution(weights_file, output_dir=\"./gating_plots\")\n",
        "else:\n",
        "    print(f\"No saved weights found at {weights_file}\")\n",
        "    print(\"Available files in ./gating_weights:\")\n",
        "    if os.path.exists(\"./gating_weights\"):\n",
        "        for f in os.listdir(\"./gating_weights\"):\n",
        "            print(f\"  - {f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "medium-skill-based-agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
