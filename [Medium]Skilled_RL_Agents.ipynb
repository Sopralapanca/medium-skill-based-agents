{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0OpfDo6BptY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIS7A-97w03Y",
        "outputId": "75f6dd4b-e180-4731-a030-7ffdca3eb5f9"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Sopralapanca/medium-skill-based-agents.git\n",
        "# %cd /content/medium-skill-based-agents\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UREODkjw6ZL",
        "outputId": "8b81adc0-24b5-468e-dec2-7c9ea6498ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uv 0.9.18 (0cee76417 2025-12-16)\n"
          ]
        }
      ],
      "source": [
        "!uv --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3VGFLkD12DN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"yes\" non ï¿½ riconosciuto come comando interno o esterno,\n",
            " un programma eseguibile o un file batch.\n"
          ]
        }
      ],
      "source": [
        "# ! yes | pip uninstall gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkFEB459xstf",
        "outputId": "edd35456-4996-4e49-d40b-15ded54316df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/Sopralapanca/atari-representation-learning.git (\u001b[2mHEAD\u001b[0m)\n",
            "    \u001b[32m\u001b[1mUpdated\u001b[0m\u001b[39m https://github.com/Sopralapanca/atari-representation-learning.git (\u001b[2meb0a9270dfd71cf19632882765f8945266e6428c\u001b[0m)\n",
            "\u001b[2mResolved \u001b[1m115 packages\u001b[0m \u001b[2min 10.94s\u001b[0m\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m atariari\u001b[2m @ git+https://github.com/Sopralapanca/atari-representation-learning.git@eb0a9270dfd71cf19632882765f8945266e6428c\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m atariari\u001b[2m @ git+https://github.com/Sopralapanca/atari-representation-learning.git@eb0a9270dfd71cf19632882765f8945266e6428c\u001b[0m\n",
            "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 1.89s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 24ms\u001b[0m\u001b[0m\n",
            "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 36ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1matariari\u001b[0m\u001b[2m==0.0.1 (from git+https://github.com/Sopralapanca/atari-representation-learning.git@6ef260a81915eee0c0d1bd99da70e80300799c7b)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1matariari\u001b[0m\u001b[2m==0.0.1 (from git+https://github.com/Sopralapanca/atari-representation-learning.git@eb0a9270dfd71cf19632882765f8945266e6428c)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !uv pip install -r pyproject.toml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ-Fqi6A2H5t",
        "outputId": "6b330c80-6639-4dab-f134-9d64cb8ae19b"
      },
      "outputs": [],
      "source": [
        "# !python create_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !python train_vos.py\n",
        "# !python train_vok.py\n",
        "# !python train_usr.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the required packages, build the environment and test if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAYAAADsNrNZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAH71JREFUeJzt3QtwlNX9//Fvks1NQhISICE1AaTYgEiVqBBMtcW0GcpQaNBKB2sURqoGlGQqmtZgLWoQW0GsQHUs6ghS8x9BsSMOxgpDDbdYrIgELKlJDQlqTQLBXEie/5zzm2xZwi2XzTebfb9mzuw+l909OSz72XOe8zwb4DiOIwAA9LDAnn5BAAAMAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCADQtwLomWeekWHDhklYWJiMHz9edu3a5a2XAgD4oABvXAvuL3/5i9x6662yevVqGz7Lly+XwsJCKS0tlcGDB5/zsa2trVJZWSn9+/eXgICA7q4aAMDLTKwcO3ZMEhISJDDwHP0cxwuuueYaJzs7273c0tLiJCQkOAUFBed9bEVFhQlECoVCoYhvF/N5fi6u7k6+pqYmKSkpkby8PPc6k4Dp6elSXFzcbv/GxkZbTk1OI01+LC4J7lJdAq4c5bHc0q9rz+cLWkKD2q37ckxIj7x2zCfN7dYFnzjZI68N/3Gm9/hXo3vmPT6glPf4hTh5slHe37HUjmSdS7cH0JdffiktLS0SFxfnsd4sHzhwoN3+BQUF8vDDD5+hYsHiCuhiAAWFei67euZNqinA1f4/Z1Boz/zdruD2r+1y8Z8T3Yv3uO8432GUbg+gjjI9pdzcXPdyXV2dJCYmSmvaWGl1hanWzRe1BrX/B68f2tIjrx39r/ZjvcH1PfLS8PP3+PFhPfMejyrjPd6duj2ABg4cKEFBQVJdXe2x3izHx8e32z80NNQWAIB/6fZp2CEhIZKSkiJFRUUeM9vMcmpqane/HADAR3llCM4MqWVlZclVV10l11xzjZ2GXV9fL7fffrs3Xg4A4IO8EkA333yzfPHFF7Jo0SKpqqqSK664QjZv3txuYgIAwH95bRLCvHnzbEHvN6Kw6bz7lE1tf5yuNez/pswDvd2I/3f+9/i/p7Sf9NQS3uqlGsHgWnAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEA+tYP0sF3NMSGnH+ngJ6oCaD3HncC+YHFnkYPCACgggACAKgggAAAKgggAIAKJiFAPp90IXtxgBa+6/MfXMhevMd7Gj0gAIAKAggAoIIAAgCo4BhQHxPU2NpuXcw/euaf2VXf3COvA/92xvf4Xt7jvogeEABABQEEAFBBAAEAVBBAAAAVvXYSQtm0EAkMv4CrNOMCtD9o6w3/vSLoDGvPtA7obrzHe5PWb1pFtp9/P3pAAAAVBBAAwDcCaNu2bTJ16lRJSEiQgIAA2bhxo8d2x3Fk0aJFMmTIEAkPD5f09HQ5dOhQd9YZAOCPx4Dq6+vlu9/9rsyePVsyMzPbbV+6dKmsWLFCXnzxRRk+fLjk5+dLRkaG7N+/X8LCwi74df45bY1E9qeDBgC+pu5Yqwy4zwsBNHnyZFvOxPR+li9fLg8++KBMmzbNrnvppZckLi7O9pRmzpzZ0ZcDAPRR3drFKCsrk6qqKjvs1iYqKkrGjx8vxcXFZ3xMY2Oj1NXVeRQAQN/XrQFkwscwPZ5TmeW2bacrKCiwIdVWEhMTu7NKAIBeSv0gS15entTW1rpLRUWFdpUAAL4WQPHx8fa2urraY71Zbtt2utDQUImMjPQoAIC+r1sDyMx6M0FTVFTkXmeO6ezcuVNSU1O786UAAD6uw7Pgjh8/Lp9++qnHxIO9e/dKTEyMJCUlyYIFC+SRRx6RkSNHuqdhm3OGpk+f3t11BwD4UwDt2bNHfvCDH7iXc3Nz7W1WVpa88MILsnDhQnuu0Ny5c6WmpkbS0tJk8+bNHToHCADQ9wU45uSdXsQM2ZnZcF8fvIQTUQHAV09EvfSwnVh2ruP6fMIDAFQQQAAAFQQQAEBFr/1Buh/umyqufqHa1QAAdNDJ+kYReeq8+9EDAgCoIIAAACoIIACACgIIAKCi105CuOjJSHG5uHoCAPiakycbLmg/ekAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQB6fwAVFBTI1VdfLf3795fBgwfL9OnTpbS01GOfhoYGyc7OltjYWImIiJAZM2ZIdXV1d9cbAOBPAbR161YbLjt27JAtW7ZIc3Oz/OhHP5L6+nr3Pjk5ObJp0yYpLCy0+1dWVkpmZqY36g4A8GEBjuM4nX3wF198YXtCJmiuu+46qa2tlUGDBsm6devkxhtvtPscOHBARo0aJcXFxTJhwoTzPmddXZ1ERUXJdWn54nKFdbZqAAAlJ082yLbti20mREZGeucYkHlyIyYmxt6WlJTYXlF6erp7n+TkZElKSrIBdCaNjY02dE4tAIC+r9MB1NraKgsWLJBrr71WxowZY9dVVVVJSEiIREdHe+wbFxdnt53tuJLp8bSVxMTEzlYJAOAPAWSOBe3bt0/Wr1/fpQrk5eXZnlRbqaio6NLzAQB8g6szD5o3b568+eabsm3bNrn44ovd6+Pj46WpqUlqamo8ekFmFpzZdiahoaG2AAD8S4d6QGa+ggmfDRs2yLvvvivDhw/32J6SkiLBwcFSVFTkXmemaZeXl0tqamr31RoA4F89IDPsZma4vf766/ZcoLbjOubYTXh4uL2dM2eO5Obm2okJZvbD/PnzbfhcyAw4AID/6FAArVq1yt5+//vf91i/Zs0aue222+z9ZcuWSWBgoD0B1cxwy8jIkJUrV3ZnnQEA/hZAF3LKUFhYmDzzzDO2AABwNlwLDgCgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAND7A2jVqlUyduxYiYyMtCU1NVXeeust9/aGhgbJzs6W2NhYiYiIkBkzZkh1dbU36g0A8KcAuvjii2XJkiVSUlIie/bskUmTJsm0adPk448/tttzcnJk06ZNUlhYKFu3bpXKykrJzMz0Vt0BAD4swHEcpytPEBMTI0888YTceOONMmjQIFm3bp29bxw4cEBGjRolxcXFMmHChAt6vrq6OomKipLr0vLF5QrrStUAAApOnmyQbdsXS21trR0t6/ZjQC0tLbJ+/Xqpr6+3Q3GmV9Tc3Czp6enufZKTkyUpKckG0Nk0Njba0Dm1AAD6vg4H0EcffWSP74SGhsqdd94pGzZskNGjR0tVVZWEhIRIdHS0x/5xcXF229kUFBTYHk9bSUxM7NxfAgDo2wH0ne98R/bu3Ss7d+6Uu+66S7KysmT//v2drkBeXp7tprWVioqKTj8XAMB3uDr6ANPL+fa3v23vp6SkyO7du+Wpp56Sm2++WZqamqSmpsajF2RmwcXHx5/1+UxPyhQAgH/p8nlAra2t9jiOCaPg4GApKipybystLZXy8nJ7jAgAgE73gMxw2eTJk+3EgmPHjtkZb++99568/fbb9vjNnDlzJDc3186MMzMf5s+fb8PnQmfAAQD8R4cC6OjRo3LrrbfKkSNHbOCYk1JN+Pzwhz+025ctWyaBgYH2BFTTK8rIyJCVK1d6q+4AAH8+D6i7cR4QAPg2r58HBABAVxBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQB8L4CWLFkiAQEBsmDBAve6hoYGyc7OltjYWImIiJAZM2ZIdXV1d9QVANCHdDqAdu/eLX/6059k7NixHutzcnJk06ZNUlhYKFu3bpXKykrJzMzsjroCAPw9gI4fPy6zZs2S5557TgYMGOBeX1tbK88//7w8+eSTMmnSJElJSZE1a9bI+++/Lzt27OjOegMA/DGAzBDblClTJD093WN9SUmJNDc3e6xPTk6WpKQkKS4uPuNzNTY2Sl1dnUcBAPR9ro4+YP369fLBBx/YIbjTVVVVSUhIiERHR3usj4uLs9vOpKCgQB5++OGOVgMA4E89oIqKCrn33ntl7dq1EhYW1i0VyMvLs0N3bcW8BgCg7+tQAJkhtqNHj8q4cePE5XLZYiYarFixwt43PZ2mpiapqanxeJyZBRcfH3/G5wwNDZXIyEiPAgDo+zo0BHfDDTfIRx995LHu9ttvt8d57r//fklMTJTg4GApKiqy06+N0tJSKS8vl9TU1O6tOQDAfwKof//+MmbMGI91/fr1s+f8tK2fM2eO5ObmSkxMjO3NzJ8/34bPhAkTurfmAAD/moRwPsuWLZPAwEDbAzIz3DIyMmTlypXd/TIAAB8X4DiOI72ImYYdFRUl16Xli8vVPRMdAAA95+TJBtm2fbGdWHau4/pcCw4AoIIAAgCoIIAAAH1jEgIAoOu+/rbnMfBjwzy3X3QkoN1jBn78jfgSekAAABUEEABABQEEAFBBAAEAVDAJAQB6oZYwz0kGzdEtnttrgsTX0QMCAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqHDpvCwA4FzCvm71WG75d5Dn9q8c8XX0gAAAKgggAEDvD6Df/va3EhAQ4FGSk5Pd2xsaGiQ7O1tiY2MlIiJCZsyYIdXV1d6oNwDA344BXXbZZfLOO+/87wlc/3uKnJwc+etf/yqFhYUSFRUl8+bNk8zMTPn73//efTUGAD8Q8XnjacvS53Q4gEzgxMfHt1tfW1srzz//vKxbt04mTZpk161Zs0ZGjRolO3bskAkTJnRPjQEA/nkM6NChQ5KQkCCXXHKJzJo1S8rLy+36kpISaW5ulvT0dPe+ZnguKSlJiouLz/p8jY2NUldX51EAAH1fhwJo/Pjx8sILL8jmzZtl1apVUlZWJt/73vfk2LFjUlVVJSEhIRIdHe3xmLi4OLvtbAoKCuxwXVtJTEzs/F8DAOibQ3CTJ0923x87dqwNpKFDh8qrr74q4eHhnapAXl6e5ObmupdND4gQAoC+r0vTsE1v59JLL5VPP/3UHhdqamqSmpoaj33MLLgzHTNqExoaKpGRkR4FAND3dSmAjh8/Lv/6179kyJAhkpKSIsHBwVJUVOTeXlpaao8RpaamdkddAQD+OgT3q1/9SqZOnWqH3SorK+Whhx6SoKAg+fnPf26P38yZM8cOp8XExNiezPz58234MAMOANClAPrPf/5jw+arr76SQYMGSVpamp1ibe4by5Ytk8DAQHsCqpndlpGRIStXruzISwAA/ESA4zi96op2ZhKC6U1dl5YvLleYdnUAAB108mSDbNu+2J4feq7j+lwLDgCgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAOAbAfT555/LLbfcIrGxsRIeHi6XX3657Nmzx73dcRxZtGiRDBkyxG5PT0+XQ4cOdXe9AQD+FEBff/21XHvttRIcHCxvvfWW7N+/X/7whz/IgAED3PssXbpUVqxYIatXr5adO3dKv379JCMjQxoaGrxRfwCAj3J1ZOfHH39cEhMTZc2aNe51w4cP9+j9LF++XB588EGZNm2aXffSSy9JXFycbNy4UWbOnNmddQcA+EsP6I033pCrrrpKbrrpJhk8eLBceeWV8txzz7m3l5WVSVVVlR12axMVFSXjx4+X4uLiMz5nY2Oj1NXVeRQAQN/XoQA6fPiwrFq1SkaOHClvv/223HXXXXLPPffIiy++aLeb8DFMj+dUZrlt2+kKCgpsSLUV08MCAPR9HQqg1tZWGTdunDz22GO29zN37ly544477PGezsrLy5Pa2lp3qaio6PRzAQD6aACZmW2jR4/2WDdq1CgpLy+39+Pj4+1tdXW1xz5muW3b6UJDQyUyMtKjAAD6vg4FkJkBV1pa6rHu4MGDMnToUPeEBBM0RUVF7u3mmI6ZDZeamtpddQYA+NssuJycHJk4caIdgvvZz34mu3btkmeffdYWIyAgQBYsWCCPPPKIPU5kAik/P18SEhJk+vTp3vobAAB9PYCuvvpq2bBhgz1u87vf/c4GjJl2PWvWLPc+CxculPr6ent8qKamRtLS0mTz5s0SFhbmjfoDAHxUgGNO3ulFzJCdmQ13XVq+uFyEFgD4mpMnG2Tb9sV2Ytm5jutzLTgAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAgAoCCACgggACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIABA7w+gYcOGSUBAQLuSnZ1ttzc0NNj7sbGxEhERITNmzJDq6mpv1R0A4C8BtHv3bjly5Ii7bNmyxa6/6aab7G1OTo5s2rRJCgsLZevWrVJZWSmZmZneqTkAwKe5OrLzoEGDPJaXLFkiI0aMkOuvv15qa2vl+eefl3Xr1smkSZPs9jVr1sioUaNkx44dMmHChO6tOQDAP48BNTU1ycsvvyyzZ8+2w3AlJSXS3Nws6enp7n2Sk5MlKSlJiouLz/o8jY2NUldX51EAAH1fpwNo48aNUlNTI7fddptdrqqqkpCQEImOjvbYLy4uzm47m4KCAomKinKXxMTEzlYJAOAPAWSG2yZPniwJCQldqkBeXp4dvmsrFRUVXXo+AEAfPAbU5rPPPpN33nlHXnvtNfe6+Ph4OyxnekWn9oLMLDiz7WxCQ0NtAQD4l071gMzkgsGDB8uUKVPc61JSUiQ4OFiKiorc60pLS6W8vFxSU1O7p7YAAP/tAbW2ttoAysrKEpfrfw83x2/mzJkjubm5EhMTI5GRkTJ//nwbPsyAAwB0OYDM0Jvp1ZjZb6dbtmyZBAYG2hNQzey2jIwMWblyZUdfAgDgBwIcx3GkFzHTsE1v6rq0fHG5wrSrAwDooJMnG2Tb9sV2YpkZDTsbrgUHAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUEEAAQBUEEAAABUEEABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBABQQQABAFQQQAAAFQQQAEAFAQQAUOGSXqpsWogEhodoVwMA0EGt37SKbD//fvSAAAAqCCAAgAoCCACgggACAKgIcBzHkV6krq5OoqKi5OuDl0hkf/IRAHxN3bFWGXDpYamtrZXIyMiz7scnPABABQEEAFBBAAEAVBBAAAAVBBAAQAUBBADo/QHU0tIi+fn5Mnz4cAkPD5cRI0bI4sWL5dSZ3Ob+okWLZMiQIXaf9PR0OXTokDfqDgDwlwB6/PHHZdWqVfLHP/5RPvnkE7u8dOlSefrpp937mOUVK1bI6tWrZefOndKvXz/JyMiQhoYGb9QfAOAPV8N+//33Zdq0aTJlyhS7PGzYMHnllVdk165d7t7P8uXL5cEHH7T7GS+99JLExcXJxo0bZebMmd74GwAAfb0HNHHiRCkqKpKDBw/a5Q8//FC2b98ukydPtstlZWVSVVVlh93amKsajB8/XoqLi8/4nI2NjfbqB6cWAEDf16Ee0AMPPGADIjk5WYKCguwxoUcffVRmzZplt5vwMUyP51RmuW3b6QoKCuThhx/u/F8AAOj7PaBXX31V1q5dK+vWrZMPPvhAXnzxRfn9739vbzsrLy/PXi+orVRUVHT6uQAAfbQHdN9999leUNuxnMsvv1w+++wz24vJysqS+Ph4u766utrOgmtjlq+44oozPmdoaKgtAAD/0qEe0IkTJyQw0PMhZiiutbXV3jfTs00ImeNEbcyQnZkNl5qa2l11BgD4Ww9o6tSp9phPUlKSXHbZZfKPf/xDnnzySZk9e7bdHhAQIAsWLJBHHnlERo4caQPJnDeUkJAg06dP99bfAADo6wFkzvcxgXL33XfL0aNHbbD88pe/tCeetlm4cKHU19fL3LlzpaamRtLS0mTz5s0SFhbmjfoDAHwUP0gHAOhW/CAdAKBXI4AAACoIIACACgIIAKCCAAIAqCCAAAAqCCAAQO8/EbUntJ2WVHf8/y7vAwDwLW2f3+c7zbTXBdCxY8fs7dBx/9auCgCgi5/n5sICPnMlBHNh08rKSunfv7+tfGJiov2JhnOdTYvOX3WC9vUe2te7aN/e274mVsznt7lc2+kXsO7VPSBT2Ysvvth9cVPD/PG8wbyH9vUu2te7aN/e2b7n6vm0YRICAEAFAQQAUNGrA8j8UupDDz3EL6Z6Ce3rXbSvd9G+vt++vW4SAgDAP/TqHhAAoO8igAAAKgggAIAKAggAoIIAAgCo6LUB9Mwzz8iwYcMkLCxMxo8fL7t27dKukk8qKCiQq6++2l7aaPDgwTJ9+nQpLS312KehoUGys7MlNjZWIiIiZMaMGVJdXa1WZ1+1ZMkSe/WOBQsWuNfRtl33+eefyy233GLbMDw8XC6//HLZs2ePe7uZyLto0SIZMmSI3Z6eni6HDh1SrbOvaGlpkfz8fBk+fLhtuxEjRsjixYs9LiLq1fZ1eqH169c7ISEhzp///Gfn448/du644w4nOjraqa6u1q6az8nIyHDWrFnj7Nu3z9m7d6/z4x//2ElKSnKOHz/u3ufOO+90EhMTnaKiImfPnj3OhAkTnIkTJ6rW29fs2rXLGTZsmDN27Fjn3nvvda+nbbvmv//9rzN06FDntttuc3bu3OkcPnzYefvtt51PP/3Uvc+SJUucqKgoZ+PGjc6HH37o/OQnP3GGDx/ufPPNN6p19wWPPvqoExsb67z55ptOWVmZU1hY6ERERDhPPfVUj7Rvrwyga665xsnOznYvt7S0OAkJCU5BQYFqvfqCo0ePmq82ztatW+1yTU2NExwcbN94bT755BO7T3FxsWJNfcexY8eckSNHOlu2bHGuv/56dwDRtl13//33O2lpaWfd3tra6sTHxztPPPGEe51p99DQUOeVV17poVr6rilTpjizZ8/2WJeZmenMmjWrR9q31w3BNTU1SUlJie3mnXqBUrNcXFysWre+oLa21t7GxMTYW9PWzc3NHu2dnJwsSUlJtPcFMkNsU6ZM8WhDg7btujfeeEOuuuoquemmm+wQ8pVXXinPPfece3tZWZlUVVV5tLG5CKYZtqeNz2/ixIlSVFQkBw8etMsffvihbN++XSZPntwj7dvrrob95Zdf2nHJuLg4j/Vm+cCBA2r16gvMT12Y4xPXXnutjBkzxq4zb66QkBCJjo5u195mG85t/fr18sEHH8ju3bvbbaNtu+7w4cOyatUqyc3NlV//+te2ne+55x7brllZWe52PNPnBW18fg888ID92QXzxSgoKMh+9j766KMya9Ysu93b7dvrAgje/aa+b98++w0HXWd+J+Xee++VLVu22Mky8M6XJtMDeuyxx+yy6QGZ9/Dq1attAKFrXn31VVm7dq2sW7dOLrvsMtm7d6/9kmp+x6cn2rfXDcENHDjQJvHpM4XMcnx8vFq9fN28efPkzTfflL/97W/u31syTJuaYc+amhqP/Wnv8zNDbEePHpVx48aJy+WyZevWrbJixQp733xLpG27xsy8Gj16tMe6UaNGSXl5ub3f1o58XnTOfffdZ3tBM2fOtLMLf/GLX0hOTo6dPdsT7dvrAsh0rVNSUuy45Knfgsxyamqqat18kZloYsJnw4YN8u6779rplqcybR0cHOzR3maatvkPTnuf2w033CAfffSR/dbYVsy3dTN80Xaftu0aM1x8+mkD5njF0KFD7X3zfjYfhKe2sRlS2rlzJ218AU6cONHuF0tNB8B85vZI+zq9dBq2mWXxwgsvOPv373fmzp1rp2FXVVVpV83n3HXXXXYK5XvvveccOXLEXU6cOOExVdhMzX733XftVOHU1FRb0HGnzoIzaNuuT293uVx2uvChQ4ectWvXOhdddJHz8ssve0wTNp8Pr7/+uvPPf/7TmTZtGtOwL1BWVpbzrW99yz0N+7XXXnMGDhzoLFy4sEfat1cGkPH000/b/7jmfCAzLXvHjh3aVfJJ5jvGmYo5N6iNeSPdfffdzoABA+x/7p/+9Kc2pND1AKJtu27Tpk3OmDFj7JfS5ORk59lnn/XYbqYK5+fnO3FxcXafG264wSktLVWrry+pq6uz71fzWRsWFuZccsklzm9+8xunsbGxR9qX3wMCAKjodceAAAD+gQACAKgggAAAKgggAIAKAggAoIIAAgCoIIAAACoIIACACgIIAKCCAAIAqCCAAACi4f8Dshd1SikFUncAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# general imports\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# training imports\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# IMPORTANT - REGISTER THE ENVIRONMENTS\n",
        "import gymnasium as gym\n",
        "import ale_py \n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# Load config\n",
        "_config_path = \"./configs.yaml\"\n",
        "\n",
        "_config = {}\n",
        "with open(_config_path, \"r\") as f:\n",
        "    _config = yaml.safe_load(f) or {}\n",
        "        \n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # ignore tensorflow warnings about CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "seed = None\n",
        "if seed is not None:    \n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "logdir = \"./tensorboard_logs\"\n",
        "\n",
        "\n",
        "env = _config.get(\"ENVS\", \"PongNoFrameskip-v4\")[0]\n",
        "with open(f'environment_configs/{env}.yaml', 'r') as file:\n",
        "        environment_configuration = yaml.safe_load(file)[\"config\"]\n",
        "\n",
        "\n",
        "environment_configuration[\"f_ext_kwargs\"][\"device\"] = device  #do not comment this, it is the parameter passed to the feature extractor\n",
        "environment_configuration[\"game\"] = env\n",
        "\n",
        "\n",
        "\n",
        "vec_envs = make_atari_env(env, n_envs=environment_configuration[\"n_envs\"], seed=seed)\n",
        "vec_envs = VecFrameStack(vec_envs, n_stack=environment_configuration[\"n_stacks\"])\n",
        "vec_envs = VecTransposeImage(vec_envs)\n",
        "\n",
        "# execute some steps with random moves\n",
        "obs = vec_envs.reset()\n",
        "\n",
        "for i in range(10):\n",
        "    action = [vec_envs.action_space.sample() for _ in range(environment_configuration[\"n_envs\"])]\n",
        "    obs, rewards, dones, info = vec_envs.step(action)\n",
        "\n",
        "# obs[0] has shape (4, 84, 84) because there are 4 stacked environments, take the first\n",
        "observation = obs[0][-1]\n",
        "plt.imshow(observation)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skills.autoencoder import Autoencoder\n",
        "from skills.unsupervised_state_representation import UnsupervisedStateRepresentationModel\n",
        "from skills.video_object_keypoints import Transporter\n",
        "from skills.video_object_segmentation import VideoObjectSegmentationModel\n",
        "from utils.feature_extractors import WeightSharingAttentionExtractor\n",
        "\n",
        "# init skills\n",
        "autoencoder = Autoencoder(channels=1).to(device)\n",
        "\n",
        "# observation has shape (32, 4, 84, 84), \n",
        "observation = obs[0][0][None, :, :] # (1, 84, 84)\n",
        "\n",
        "usr = UnsupervisedStateRepresentationModel(observation=observation, device=device)\n",
        "vok = Transporter().to(device)\n",
        "vos = VideoObjectSegmentationModel(device=device)\n",
        "\n",
        "\n",
        "skills = [\n",
        "    usr.get_skill(device=device),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"encoder\"),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"keynet\"),\n",
        "    vos.get_skill(device=device)\n",
        "]\n",
        "\n",
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "\n",
        "environment_configuration[\"f_ext_name\"] = \"wsharing_attention_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = WeightSharingAttentionExtractor\n",
        "\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=environment_configuration[\"f_ext_class\"],\n",
        "    features_extractor_kwargs=f_ext_kwargs,\n",
        "    net_arch={\n",
        "        'pi': environment_configuration[\"net_arch_pi\"],\n",
        "        'vf': environment_configuration[\"net_arch_vf\"]\n",
        "    },\n",
        "    #activation_fn=th.nn.ReLU,  # use ReLU in case of multiple layers for the policy learning network\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [32, 1, 8, 8], expected input[1, 4, 160, 210] to have 1 channels, but got 4 channels instead",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m eval_env = VecFrameStack(eval_env, n_stack=environment_configuration[\u001b[33m\"\u001b[39m\u001b[33mn_stacks\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      8\u001b[39m eval_env = VecTransposeImage(eval_env)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m model = \u001b[43mPPO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCnnPolicy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvec_envs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinear_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclip_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinear_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclip_range\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnormalize_advantage\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnormalize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ment_coef\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvf_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_configuration\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvf_coef\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:171\u001b[39m, in \u001b[36mPPO.__init__\u001b[39m\u001b[34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28mself\u001b[39m.target_kl = target_kl\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:174\u001b[39m, in \u001b[36mPPO._setup_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;66;03m# Initialize schedules for policy/value clipping\u001b[39;00m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m.clip_range = FloatSchedule(\u001b[38;5;28mself\u001b[39m.clip_range)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:135\u001b[39m, in \u001b[36mOnPolicyAlgorithm._setup_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28mself\u001b[39m.rollout_buffer_class = RolloutBuffer\n\u001b[32m    125\u001b[39m \u001b[38;5;28mself\u001b[39m.rollout_buffer = \u001b[38;5;28mself\u001b[39m.rollout_buffer_class(\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_steps,\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m.observation_space,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    133\u001b[39m     **\u001b[38;5;28mself\u001b[39m.rollout_buffer_kwargs,\n\u001b[32m    134\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28mself\u001b[39m.policy = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28mself\u001b[39m.policy = \u001b[38;5;28mself\u001b[39m.policy.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Warn when not using CPU with MlpPolicy\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:818\u001b[39m, in \u001b[36mActorCriticCnnPolicy.__init__\u001b[39m\u001b[34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[39m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    799\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    800\u001b[39m     observation_space: spaces.Space,\n\u001b[32m   (...)\u001b[39m\u001b[32m    816\u001b[39m     optimizer_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    817\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mortho_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_std_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_expln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43msquash_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshare_features_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:507\u001b[39m, in \u001b[36mActorCriticPolicy.__init__\u001b[39m\u001b[34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28mself\u001b[39m.ortho_init = ortho_init\n\u001b[32m    506\u001b[39m \u001b[38;5;28mself\u001b[39m.share_features_extractor = share_features_extractor\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[38;5;28mself\u001b[39m.features_extractor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.features_dim = \u001b[38;5;28mself\u001b[39m.features_extractor.features_dim\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.share_features_extractor:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:120\u001b[39m, in \u001b[36mBaseModel.make_features_extractor\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_features_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> BaseFeaturesExtractor:\n\u001b[32m    119\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Helper method to create a features extractor.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\utils\\feature_extractors.py:112\u001b[39m, in \u001b[36mWeightSharingAttentionExtractor.__init__\u001b[39m\u001b[34m(self, observation_space, features_dim, skills, device)\u001b[39m\n\u001b[32m    108\u001b[39m sample = sample.to(device)\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m#dropout_p = 0.1\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# this will populate self.skills_embeddings\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# linear layers to learn a representation of the skills\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.mlp_layers = nn.ModuleList()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\utils\\feature_extractors.py:73\u001b[39m, in \u001b[36mFeaturesExtractor.preprocess_input\u001b[39m\u001b[34m(self, observations)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     72\u001b[39m     so = skill.input_adapter(observations)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     so = \u001b[43mskill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskill_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskill\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskill_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mso\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# can return linear or spatial embeddings\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# from spatial to linear embeddings if needed        \u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skill.name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.adapters:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\skills\\skill_interface.py:10\u001b[39m, in \u001b[36mmodel_forward\u001b[39m\u001b[34m(model, x)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_forward\u001b[39m(model, x):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Default forward wrapper for skill models.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\atariari\\methods\\encoders.py:161\u001b[39m, in \u001b[36mNatureCNN.forward\u001b[39m\u001b[34m(self, inputs, fmaps)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, fmaps=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     f5 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     f7 = \u001b[38;5;28mself\u001b[39m.main[\u001b[32m6\u001b[39m:\u001b[32m8\u001b[39m](f5)\n\u001b[32m    163\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.main[\u001b[32m8\u001b[39m:](f7)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\giaco\\VSCode Projects\\medium-articles\\skill-based-agents\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [32, 1, 8, 8], expected input[1, 4, 160, 210] to have 1 channels, but got 4 channels instead"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from rl_zoo3.utils import linear_schedule\n",
        "\n",
        "\n",
        "\n",
        "eval_env = make_atari_env(env, n_envs=environment_configuration[\"n_envs\"])\n",
        "eval_env = VecFrameStack(eval_env, n_stack=environment_configuration[\"n_stacks\"])\n",
        "eval_env = VecTransposeImage(eval_env)\n",
        "\n",
        "\n",
        "model = PPO(\"CnnPolicy\",\n",
        "            vec_envs,\n",
        "            learning_rate=linear_schedule(environment_configuration[\"learning_rate\"]),\n",
        "            n_steps=128,\n",
        "            n_epochs=4,\n",
        "            batch_size=environment_configuration[\"batch_size\"],\n",
        "            clip_range=linear_schedule(environment_configuration[\"clip_range\"]),\n",
        "            normalize_advantage=environment_configuration[\"normalize\"],\n",
        "            ent_coef=environment_configuration[\"ent_coef\"],\n",
        "            vf_coef=environment_configuration[\"vf_coef\"],\n",
        "            policy_kwargs=policy_kwargs,\n",
        "            verbose=0,\n",
        "            device=device,\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_id = \"test_run_1_wsa\"\n",
        "gamelogs = f\"{logdir}/{env}/{run_id}\"\n",
        "os.makedirs(gamelogs, exist_ok=True)\n",
        "\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    n_eval_episodes=100,\n",
        "    best_model_save_path=f\"./agents/{run_id}\",\n",
        "    log_path=gamelogs,\n",
        "    eval_freq=5000 * environment_configuration[\"n_envs\"],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    eval_callback\n",
        "]\n",
        "\n",
        "model.learn(\n",
        "    environment_configuration[\"n_timesteps\"],\n",
        "    callback=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMtMYo6f1slK1K86xPI/xkL",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "skill-based-agents (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
