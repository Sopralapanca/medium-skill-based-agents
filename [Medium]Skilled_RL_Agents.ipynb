{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0OpfDo6BptY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIS7A-97w03Y",
        "outputId": "57a0547e-26a8-471d-a917-332aa8868d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'medium-skill-based-agents'...\n",
            "remote: Enumerating objects: 17466, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 17466 (delta 8), reused 20 (delta 7), pack-reused 17439 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17466/17466), 153.10 MiB | 11.17 MiB/s, done.\n",
            "Resolving deltas: 100% (7866/7866), done.\n",
            "Updating files: 100% (33/33), done.\n",
            "/content/medium-skill-based-agents\n",
            " agents\t\t\t\t    pyproject.toml     train_autoenc.py\n",
            " configs.yaml\t\t\t    README.md\t       train_usr.py\n",
            " convert_to_pt.py\t\t    skills\t       train_vok.py\n",
            " create_dataset.py\t\t    test_packages.py   train_vos.py\n",
            " environment_configs\t\t    test_train.py      utils\n",
            " MANIFEST.in\t\t\t    test_vok.ipynb     uv.lock\n",
            "'[Medium]Skilled_RL_Agents.ipynb'   test_vos.ipynb\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/Sopralapanca/medium-skill-based-agents.git\n",
        "# %cd /content/medium-skill-based-agents\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UREODkjw6ZL",
        "outputId": "956bf22f-297e-4f4f-c6ac-a695484b050e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uv 0.9.17\n"
          ]
        }
      ],
      "source": [
        "!uv --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3VGFLkD12DN"
      },
      "outputs": [],
      "source": [
        "# ! yes | pip uninstall gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkFEB459xstf",
        "outputId": "9b872278-6cb9-4c2c-96b8-80d8d98e25bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m148 packages\u001b[0m \u001b[2min 7.55s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m45 packages\u001b[0m \u001b[2min 1m 19s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m11 packages\u001b[0m \u001b[2min 1.98s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m45 packages\u001b[0m \u001b[2min 990ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1matariari\u001b[0m\u001b[2m==0.0.1 (from git+https://github.com/Sopralapanca/atari-representation-learning.git@9cc4c53fa44f45c14061343b57e8a40e25945028)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.10.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdataproperty\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgym\u001b[0m\u001b[2m==0.25.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgym\u001b[0m\u001b[2m==0.26.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgymnasium\u001b[0m\u001b[2m==1.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgymnasium\u001b[0m\u001b[2m==1.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-sb3\u001b[0m\u001b[2m==3.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.17.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==7.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia\u001b[0m\u001b[2m==0.8.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia-rs\u001b[0m\u001b[2m==0.1.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmbstrdecoder\u001b[0m\u001b[2m==1.1.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mmoviepy\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmoviepy\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.28.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpathvalidate\u001b[0m\u001b[2m==3.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytablewriter\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrl-zoo3\u001b[0m\u001b[2m==2.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msb3-contrib\u001b[0m\u001b[2m==2.7.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mshimmy\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstable-baselines3\u001b[0m\u001b[2m==2.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtabledata\u001b[0m\u001b[2m==1.3.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtcolorpy\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.19.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.20.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtensorflow\u001b[0m\u001b[2m==2.19.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtensorflow\u001b[0m\u001b[2m==2.20.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0+cpu\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0+cpu\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtypepy\u001b[0m\u001b[2m==1.3.4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !uv pip install -r pyproject.toml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ-Fqi6A2H5t"
      },
      "outputs": [],
      "source": [
        "# !python create_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PiyVRcgMUdK"
      },
      "outputs": [],
      "source": [
        "# !python train_vos.py\n",
        "# !python train_vok.py\n",
        "# !python train_usr.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_C88ROwMUdL"
      },
      "source": [
        "Import the required packages, build the environment and test if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1xZN1JaoBj4",
        "outputId": "19907a38-ba08-464a-9825-9b18e54c4154"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        }
      ],
      "source": [
        "# general imports\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# training imports\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# IMPORTANT - REGISTER THE ENVIRONMENTS\n",
        "import gymnasium as gym\n",
        "import ale_py\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "# Load config\n",
        "_config_path = \"./configs.yaml\"\n",
        "\n",
        "_config = {}\n",
        "with open(_config_path, \"r\") as f:\n",
        "    _config = yaml.safe_load(f) or {}\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # ignore tensorflow warnings about CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "seed = None\n",
        "if seed is not None:\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "#envs = _config.get(\"ENVS\", [\"PongNoFrameskip-v4\"])[0]\n",
        "env = \"PongNoFrameskip-v4\"\n",
        "with open(f'environment_configs/{env}.yaml', 'r') as file:\n",
        "        environment_configuration = yaml.safe_load(file)[\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_env(env_id, configs, seed=None):\n",
        "    env = make_atari_env(env_id, n_envs=configs[\"n_envs\"], seed=seed)\n",
        "    env = VecFrameStack(env, n_stack=configs[\"n_stacks\"])\n",
        "    env = VecTransposeImage(env)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KjcYdvrRWjXI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "# key = os.getenv(\"WANDB_API_KEY\")\n",
        "# if key is None:\n",
        "#     raise ValueError(\"WANDB_API_KEY not set\")\n",
        "\n",
        "# wandb.login(key=key)\n",
        "\n",
        "# tags = [\n",
        "#     f\"fe:{environment_configuration['f_ext_name']}\",\n",
        "#     f\"game:{environment_configuration['game']}\",\n",
        "# ]\n",
        "\n",
        "# run = wandb.init(\n",
        "#     project=\"medium-skill-based-agents\",\n",
        "#     config=environment_configuration,\n",
        "#     sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "#     monitor_gym=False,  # auto-upload the videos of agents playing the game\n",
        "#     group=f\"{environment_configuration['game']}\",\n",
        "#     tags=tags\n",
        "#     # save_code = True,  # optional\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "wolJs-iNMUdL",
        "outputId": "380143db-de7f-4eb8-d65b-23f0f6b49e2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_envs = create_env(env_id=env, configs=environment_configuration, seed=seed)\n",
        "\n",
        "# execute some steps with random moves\n",
        "obs = test_envs.reset()\n",
        "\n",
        "for i in range(10):\n",
        "    action = [test_envs.action_space.sample() for _ in range(environment_configuration[\"n_envs\"])]\n",
        "    obs, rewards, dones, info = test_envs.step(action)\n",
        "\n",
        "# obs[0] has shape (4, 84, 84) because there are 4 stacked environments, take the first\n",
        "observation = obs[0][-1]\n",
        "plt.imshow(observation)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility function for training agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from stable_baselines3 import PPO\n",
        "from rl_zoo3.utils import linear_schedule\n",
        "\n",
        "\n",
        "def train_agent(env_id, configs, policy_kwargs, seed):\n",
        "    \n",
        "    logdir = \"./tensorboard_logs\"\n",
        "    \n",
        "    # monitor_dir = f\"monitor/{run.id}\"\n",
        "    monitor_dir = \"ppo\"\n",
        "\n",
        "    vec_envs = create_env(env_id=env_id, configs=configs, seed=seed)\n",
        "    _ = vec_envs.reset()\n",
        "    \n",
        "    eval_envs = create_env(env_id=env_id, configs=configs, seed=None)\n",
        "\n",
        "    model = PPO(\n",
        "        \"CnnPolicy\",\n",
        "        vec_envs,\n",
        "        learning_rate=linear_schedule(environment_configuration[\"learning_rate\"]),\n",
        "        n_steps=128,\n",
        "        n_epochs=4,\n",
        "        batch_size=environment_configuration[\"batch_size\"],\n",
        "        clip_range=linear_schedule(environment_configuration[\"clip_range\"]),\n",
        "        normalize_advantage=environment_configuration[\"normalize\"],\n",
        "        ent_coef=environment_configuration[\"ent_coef\"],\n",
        "        vf_coef=environment_configuration[\"vf_coef\"],\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        verbose=1,\n",
        "        device=device,\n",
        "        tensorboard_log=logdir,\n",
        "    )\n",
        "\n",
        "\n",
        "    eval_logs = f\"eval_logs/{env}/{monitor_dir}\"\n",
        "    os.makedirs(eval_logs, exist_ok=True)\n",
        "\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_envs,\n",
        "        n_eval_episodes=100,\n",
        "        best_model_save_path=f\"./agents/{monitor_dir}\",\n",
        "        log_path=eval_logs,\n",
        "        eval_freq=5000 * environment_configuration[\"n_envs\"],\n",
        "        verbose=0,\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        #WandbCallback(verbose=0),\n",
        "        eval_callback\n",
        "    ]\n",
        "\n",
        "    model.learn(2000, callback=callbacks) #tb_log_name=run.id)\n",
        "    #run.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train Standard PPO Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Logging to ./tensorboard_logs/PPO_9\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 830  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 1    |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 488           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 4             |\n",
            "|    total_timesteps      | 2048          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00067645044 |\n",
            "|    clip_fraction        | 0.133         |\n",
            "|    clip_range           | 0.0488        |\n",
            "|    entropy_loss         | -1.79         |\n",
            "|    explained_variance   | -0.0494       |\n",
            "|    learning_rate        | 0.000122      |\n",
            "|    loss                 | 0.0242        |\n",
            "|    n_updates            | 4             |\n",
            "|    policy_gradient_loss | -0.00183      |\n",
            "|    value_loss           | 0.206         |\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch={\n",
        "        \"pi\": environment_configuration[\"net_arch_pi\"],\n",
        "        \"vf\": environment_configuration[\"net_arch_vf\"],\n",
        "    },\n",
        "    # activation_fn=torch.nn.ReLU,  # use ReLU in case of multiple layers for the policy learning network\n",
        ")\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_98s5PWMUdM",
        "outputId": "45789a98-3844-47b1-82fa-e3664cde07d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 84, 84)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/giacomo/Documents/code-projects/medium-skill-based-agents/.venv/lib/python3.12/site-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing skill input adapters:\n",
            "\n",
            "Skill: state_rep_uns\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 160, 210])\n",
            "\n",
            "Skill: obj_key_enc\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: obj_key_key\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: vid_obj_seg\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 2, 84, 84])\n"
          ]
        }
      ],
      "source": [
        "from skills.autoencoder import Autoencoder\n",
        "from skills.unsupervised_state_representation import UnsupervisedStateRepresentationModel\n",
        "from skills.video_object_keypoints import Transporter\n",
        "from skills.video_object_segmentation import VideoObjectSegmentationModel\n",
        "\n",
        "# init skills\n",
        "autoencoder = Autoencoder(channels=1).to(device)\n",
        "\n",
        "# observation has shape (32, 4, 84, 84),\n",
        "# observation = obs[0][0][None, :, :] # (1, 84, 84)\n",
        "\n",
        "print(obs[0].shape) # (4, 84, 84)\n",
        "\n",
        "environment_configuration[\"f_ext_kwargs\"][\"device\"] = device  #do not comment this, it is the parameter passed to the feature extractor\n",
        "environment_configuration[\"game\"] = env\n",
        "\n",
        "\n",
        "usr = UnsupervisedStateRepresentationModel(observation=obs[0], device=device)\n",
        "vok = Transporter().to(device)\n",
        "vos = VideoObjectSegmentationModel(device=device)\n",
        "\n",
        "\n",
        "skills = [\n",
        "    usr.get_skill(device=device),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"encoder\"),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"keynet\"),\n",
        "    vos.get_skill(device=device)\n",
        "]\n",
        "\n",
        "# Test each skill's input adapter\n",
        "print(\"\\nTesting skill input adapters:\")\n",
        "test_obs = obs[:1]  # Take one sample from batch\n",
        "test_obs = torch.tensor(test_obs, dtype=torch.float32).to(device)\n",
        "\n",
        "for skill in skills:\n",
        "    print(f\"\\nSkill: {skill.name}\")\n",
        "    print(f\"Input shape: {test_obs.shape}\")\n",
        "    adapted = skill.input_adapter(test_obs)\n",
        "    print(f\"After adapter: {adapted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train WSA agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Logging to ./tensorboard_logs/PPO_10\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 66   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 15   |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 19           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 2048         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008237411 |\n",
            "|    clip_fraction        | 0.123        |\n",
            "|    clip_range           | 0.0488       |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -0.013       |\n",
            "|    learning_rate        | 0.000122     |\n",
            "|    loss                 | 0.0236       |\n",
            "|    n_updates            | 4            |\n",
            "|    policy_gradient_loss | -0.000502    |\n",
            "|    value_loss           | 0.187        |\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from utils.feature_extractors import WeightSharingAttentionExtractor\n",
        "\n",
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "environment_configuration[\"f_ext_name\"] = \"wsharing_attention_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = WeightSharingAttentionExtractor\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)\n",
        "\n",
        "\n",
        "# elif feature_extractor_class == \"moe\":\n",
        "#     environment_configuration[\"f_ext_name\"] = \"moe_ext\"\n",
        "#     environment_configuration[\"f_ext_class\"] = MixtureOfExpertsExtractor\n",
        "# elif feature_extractor_class == \"ppo\":\n",
        "#     pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train MOE agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Logging to ./tensorboard_logs/PPO_11\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 99   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 10   |\n",
            "|    total_timesteps | 1024 |\n",
            "-----------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 21            |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 96            |\n",
            "|    total_timesteps      | 2048          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00053051766 |\n",
            "|    clip_fraction        | 0.0938        |\n",
            "|    clip_range           | 0.0488        |\n",
            "|    entropy_loss         | -1.79         |\n",
            "|    explained_variance   | -0.285        |\n",
            "|    learning_rate        | 0.000122      |\n",
            "|    loss                 | 0.0307        |\n",
            "|    n_updates            | 4             |\n",
            "|    policy_gradient_loss | -0.00119      |\n",
            "|    value_loss           | 0.574         |\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from utils.feature_extractors import MixtureOfExpertsExtractor\n",
        "\n",
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "environment_configuration[\"f_ext_name\"] = \"moe_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = MixtureOfExpertsExtractor\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "medium-skill-based-agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
