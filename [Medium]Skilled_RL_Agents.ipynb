{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0OpfDo6BptY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIS7A-97w03Y",
        "outputId": "57a0547e-26a8-471d-a917-332aa8868d9c"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Sopralapanca/medium-skill-based-agents.git\n",
        "# %cd /content/medium-skill-based-agents\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkFEB459xstf",
        "outputId": "9b872278-6cb9-4c2c-96b8-80d8d98e25bf"
      },
      "outputs": [],
      "source": [
        "# !uv pip install -r pyproject.toml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate dataset for pretrained skills and train skill-based RL agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ-Fqi6A2H5t"
      },
      "outputs": [],
      "source": [
        "# !python create_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PiyVRcgMUdK"
      },
      "outputs": [],
      "source": [
        "# !python train_vos.py\n",
        "# !python train_vok.py\n",
        "# !python train_usr.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_C88ROwMUdL"
      },
      "source": [
        "Import the required packages, build the environment and test if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1xZN1JaoBj4",
        "outputId": "19907a38-ba08-464a-9825-9b18e54c4154"
      },
      "outputs": [],
      "source": [
        "# general imports\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# IMPORTANT - REGISTER THE ENVIRONMENTS\n",
        "import gymnasium as gym\n",
        "import ale_py\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # ignore tensorflow warnings about CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "seed = None\n",
        "if seed is not None:\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "def load_env_config(env):\n",
        "    with open(f'environment_configs/{env}.yaml', 'r') as file:\n",
        "        environment_configuration = yaml.safe_load(file)[\"config\"]\n",
        "    return environment_configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\VSCodeProjects\\medium-skill-based-agents\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
        "\n",
        "def create_env(env_id, configs, seed=None):\n",
        "    env = make_atari_env(env_id, n_envs=configs[\"n_envs\"], seed=seed)\n",
        "    env = VecFrameStack(env, n_stack=configs[\"n_stacks\"])\n",
        "    env = VecTransposeImage(env)\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KjcYdvrRWjXI"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "key = os.getenv(\"WANDB_API_KEY\")\n",
        "if key is None:\n",
        "    raise ValueError(\"WANDB_API_KEY not set\")\n",
        "\n",
        "def init_wandb(environment_configuration):\n",
        "  wandb.login(key=key)\n",
        "\n",
        "  tags = [\n",
        "      f\"fe:{environment_configuration['f_ext_name']}\",\n",
        "      f\"game:{environment_configuration['game']}\",\n",
        "  ]\n",
        "\n",
        "  run = wandb.init(\n",
        "      project=\"medium-skill-based-agents\",\n",
        "      config=environment_configuration,\n",
        "      sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "      monitor_gym=False,  # auto-upload the videos of agents playing the game\n",
        "      group=f\"{environment_configuration['game']}\",\n",
        "      tags=tags\n",
        "      # save_code = True,  # optional\n",
        "  )\n",
        "\n",
        "  return run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test the environment creation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "wolJs-iNMUdL",
        "outputId": "380143db-de7f-4eb8-d65b-23f0f6b49e2d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "env = \"PongNoFrameskip-v4\"\n",
        "environment_configuration = load_env_config(env)\n",
        "\n",
        "test_envs = create_env(env_id=env, configs=environment_configuration, seed=seed)\n",
        "\n",
        "# execute some steps with random moves\n",
        "obs = test_envs.reset()\n",
        "\n",
        "for i in range(10):\n",
        "    action = [test_envs.action_space.sample() for _ in range(environment_configuration[\"n_envs\"])]\n",
        "    obs, rewards, dones, info = test_envs.step(action)\n",
        "\n",
        "# obs[0] has shape (4, 84, 84) because there are 4 stacked environments, take the first\n",
        "observation = obs[0][-1]\n",
        "plt.imshow(observation)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility function for training agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from utils.custom_ppo import CustomPPO  # Use custom PPO with auxiliary loss support\n",
        "from rl_zoo3.utils import linear_schedule\n",
        "from utils.monitor_weights import GatingMonitorCallback\n",
        "\n",
        "def train_agent(env_id, configs, policy_kwargs, seed):\n",
        "    \n",
        "    run = init_wandb(configs)\n",
        "    logdir = \"./tensorboard_logs\"\n",
        "    \n",
        "    monitor_dir = str(run.id)\n",
        "    \n",
        "    vec_envs = create_env(env_id=env_id, configs=configs, seed=seed)\n",
        "    _ = vec_envs.reset()\n",
        "    \n",
        "    #eval_envs = create_env(env_id=env_id, configs=configs, seed=None)\n",
        "\n",
        "    model = CustomPPO( \n",
        "        \"CnnPolicy\",\n",
        "        vec_envs,\n",
        "        learning_rate=linear_schedule(environment_configuration[\"learning_rate\"]),\n",
        "        n_steps=environment_configuration[\"n_steps\"],\n",
        "        n_epochs=environment_configuration[\"n_epochs\"],\n",
        "        batch_size=environment_configuration[\"batch_size\"],\n",
        "        clip_range=linear_schedule(environment_configuration[\"clip_range\"]),\n",
        "        normalize_advantage=environment_configuration[\"normalize\"],\n",
        "        ent_coef=environment_configuration[\"ent_coef\"],\n",
        "        vf_coef=environment_configuration[\"vf_coef\"],\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        verbose=0,\n",
        "        device=device,\n",
        "        tensorboard_log=logdir,\n",
        "    )\n",
        "\n",
        "\n",
        "    eval_logs = f\"eval_logs/{env}/{monitor_dir}\"\n",
        "    os.makedirs(eval_logs, exist_ok=True)\n",
        "\n",
        "    # eval_callback = EvalCallback(\n",
        "    #     eval_envs,\n",
        "    #     n_eval_episodes=100,\n",
        "    #     best_model_save_path=f\"./agents/{monitor_dir}\",\n",
        "    #     log_path=eval_logs,\n",
        "    #     eval_freq=5000 * environment_configuration[\"n_envs\"],\n",
        "    #     verbose=0,\n",
        "    # )\n",
        "    \n",
        "    \n",
        "    callbacks = [\n",
        "        WandbCallback(verbose=0),\n",
        "        # eval_callback\n",
        "    ]\n",
        "\n",
        "    if configs[\"f_ext_name\"] == \"wsharing_attention_ext\":\n",
        "        # Get the feature extractor from the model\n",
        "        feature_extractor = model.policy.features_extractor\n",
        "\n",
        "        # Create monitoring callback\n",
        "        gating_monitor = GatingMonitorCallback(\n",
        "            feature_extractor=feature_extractor,\n",
        "            env=env_id,\n",
        "            save_freq=5000,  # Save every 5000 steps\n",
        "            save_path=f\"./{configs[\"f_ext_name\"]}_weights\",\n",
        "            verbose=0,\n",
        "            run_id=monitor_dir\n",
        "        )\n",
        "        \n",
        "        callbacks.append(gating_monitor)\n",
        "        \n",
        "    model.learn(1000000, callback=callbacks, progress_bar=True)\n",
        "    run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch={\n",
        "        \"pi\": environment_configuration[\"net_arch_pi\"],\n",
        "        \"vf\": environment_configuration[\"net_arch_vf\"],\n",
        "    },\n",
        "    # activation_fn=torch.nn.ReLU,  # use ReLU in case of multiple layers for the policy learning network\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Skills initialization for RL agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing skill input adapters:\n",
            "\n",
            "Skill: state_rep_uns\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 160, 210])\n",
            "\n",
            "Skill: obj_key_enc\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: obj_key_key\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 1, 84, 84])\n",
            "\n",
            "Skill: vid_obj_seg\n",
            "Input shape: torch.Size([1, 4, 84, 84])\n",
            "After adapter: torch.Size([1, 2, 84, 84])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\VSCodeProjects\\medium-skill-based-agents\\.venv\\Lib\\site-packages\\torch\\functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4319.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "from skills.video_object_segmentation import VideoObjectSegmentationModel\n",
        "from skills.video_object_keypoints import Transporter\n",
        "from skills.autoencoder import Autoencoder\n",
        "from skills.unsupervised_state_representation import UnsupervisedStateRepresentationModel\n",
        "\n",
        "# init skills\n",
        "autoencoder = Autoencoder(channels=1).to(device)\n",
        "\n",
        "environment_configuration[\"f_ext_kwargs\"][\"device\"] = device \n",
        "environment_configuration[\"game\"] = env\n",
        "\n",
        "\n",
        "usr = UnsupervisedStateRepresentationModel(observation=obs[0], device=device)\n",
        "vok = Transporter().to(device)\n",
        "vos = VideoObjectSegmentationModel(device=device)\n",
        "\n",
        "\n",
        "skills = [\n",
        "    usr.get_skill(device=device),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"encoder\"),\n",
        "    vok.get_skill(device=device, keynet_or_encoder=\"keynet\"),\n",
        "    vos.get_skill(device=device)\n",
        "]\n",
        "\n",
        "# Test each skill's input adapter\n",
        "print(\"\\nTesting skill input adapters:\")\n",
        "test_obs = obs[:1]  # Take one sample from batch\n",
        "test_obs = torch.tensor(test_obs, dtype=torch.float32).to(device)\n",
        "\n",
        "for skill in skills:\n",
        "    print(f\"\\nSkill: {skill.name}\")\n",
        "    print(f\"Input shape: {test_obs.shape}\")\n",
        "    adapted = skill.input_adapter(test_obs)\n",
        "    print(f\"After adapter: {adapted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = \"PongNoFrameskip-v4\"\n",
        "environment_configuration = load_env_config(env)\n",
        "environment_configuration[\"game\"] = env\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Standard PPO Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train WSA agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.feature_extractors import WeightSharingAttentionExtractor\n",
        "\n",
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "environment_configuration[\"f_ext_name\"] = \"wsharing_attention_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = WeightSharingAttentionExtractor\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Breakout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = \"BreakoutNoFrameskip-v4\"\n",
        "environment_configuration = load_env_config(env)\n",
        "environment_configuration[\"game\"] = env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\giaco\\_netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjames101\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>f:\\VSCodeProjects\\medium-skill-based-agents\\wandb\\run-20260109_225417-mm5g684o</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/james101/medium-skill-based-agents/runs/mm5g684o' target=\"_blank\">warm-field-52</a></strong> to <a href='https://wandb.ai/james101/medium-skill-based-agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/james101/medium-skill-based-agents' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/james101/medium-skill-based-agents/runs/mm5g684o' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents/runs/mm5g684o</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef8052a664924d83b9c36f24ab96afb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▂▂▂▂▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▁▂▂▂▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>time/fps</td><td>███▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/approx_kl</td><td>▃▁▃▆██▄▄▄▆▄▄▅▅▃▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/clip_fraction</td><td>▁▃▂▄▅▄▆▅▇▆▅▄▅▆▆▇▆▇▆▆▆▆█▆▆▆▆▆▇▆▇▇▇█▆▆▇▇▆▇</td></tr><tr><td>train/clip_range</td><td>████▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▁▁▂▃▆▇▇██▇▆▆▆▆▅▅▅▆▅▅▆▅▆▆▅▅▅▆▆▅▆▆▆▅▅▅▅▅▅</td></tr><tr><td>train/explained_variance</td><td>▁▇█▇█▇▇▆▇▆▆▆▇▆█▇▆█▇▇▆▇▇▇▇▇▇▆▆▇█▇▇▇▆▆▇▇▆▆</td></tr><tr><td>train/learning_rate</td><td>██████▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▁</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>1000448</td></tr><tr><td>rollout/ep_len_mean</td><td>2534.32</td></tr><tr><td>rollout/ep_rew_mean</td><td>17.45</td></tr><tr><td>time/fps</td><td>758</td></tr><tr><td>train/approx_kl</td><td>0.0</td></tr><tr><td>train/clip_fraction</td><td>0.26074</td></tr><tr><td>train/clip_range</td><td>6e-05</td></tr><tr><td>train/entropy_loss</td><td>-0.95532</td></tr><tr><td>train/explained_variance</td><td>0.76248</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">warm-field-52</strong> at: <a href='https://wandb.ai/james101/medium-skill-based-agents/runs/mm5g684o' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents/runs/mm5g684o</a><br> View project at: <a href='https://wandb.ai/james101/medium-skill-based-agents' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20260109_225417-mm5g684o\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "WSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "environment_configuration[\"f_ext_name\"] = \"wsharing_attention_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = WeightSharingAttentionExtractor\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MsPacman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = \"MsPacmanNoFrameskip-v4\"\n",
        "environment_configuration = load_env_config(env)\n",
        "environment_configuration[\"game\"] = env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\giaco\\_netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>f:\\VSCodeProjects\\medium-skill-based-agents\\wandb\\run-20260109_231623-okl8wxve</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/james101/medium-skill-based-agents/runs/okl8wxve' target=\"_blank\">fragrant-wind-53</a></strong> to <a href='https://wandb.ai/james101/medium-skill-based-agents' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/james101/medium-skill-based-agents' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/james101/medium-skill-based-agents/runs/okl8wxve' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents/runs/okl8wxve</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20ae42b4c3dd4a9ab9fc1924987ce19b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>rollout/ep_len_mean</td><td>▂▁▃▆▆████▇▇▇▇▆▇▆▆▆▆▆█▇▆▆▆▆▆▆▆▆▅▅▅▅▅▆▅▅▆▆</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▂▂▃▃▆▆▆▇▇▇▇▇▇▇▇▆▆▆▆▇▇███▆▆▆▆▆▆▆▇▇▆▆▆▇▇▇</td></tr><tr><td>time/fps</td><td>▅▁▄▅▆▆▆▆▆▇▇▇▇▇██████████████████████████</td></tr><tr><td>train/approx_kl</td><td>▂▁▂▂▂▂▃▃▂▂▂▂▃▃▄▄▂▂▂▃█▃▆▄▇▅▄▄▄▂▅▂▁▂▁▁▂▁▁▁</td></tr><tr><td>train/clip_fraction</td><td>▂▁▁▄▂▂▃▃▃▄▂▃▂▂▃▄▅▅▄▅▅▇▆▄▇▄▇▇▇██▄█▇▆█▇▆▇▇</td></tr><tr><td>train/clip_range</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▁▂▂▃▆▆▇▅▆▇▇▅▅▅▄▆▅▆▇▇▆▇▇▅█▇▆▆▆▄▆▇█▆▆▆▅█▇</td></tr><tr><td>train/explained_variance</td><td>▅▇▃▇▆▅█▆▃▇▁▇▇▇▆▇▆▄▅█▆█▆█▇▅▆▆█▇▇█▇▆▆▇▆▅▇▅</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>1000448</td></tr><tr><td>rollout/ep_len_mean</td><td>2486.12</td></tr><tr><td>rollout/ep_rew_mean</td><td>637.9</td></tr><tr><td>time/fps</td><td>865</td></tr><tr><td>train/approx_kl</td><td>0.0</td></tr><tr><td>train/clip_fraction</td><td>0.7854</td></tr><tr><td>train/clip_range</td><td>6e-05</td></tr><tr><td>train/entropy_loss</td><td>-1.69102</td></tr><tr><td>train/explained_variance</td><td>0.92674</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fragrant-wind-53</strong> at: <a href='https://wandb.ai/james101/medium-skill-based-agents/runs/okl8wxve' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents/runs/okl8wxve</a><br> View project at: <a href='https://wandb.ai/james101/medium-skill-based-agents' target=\"_blank\">https://wandb.ai/james101/medium-skill-based-agents</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20260109_231623-okl8wxve\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "environment_configuration[\"f_ext_name\"] = \"wsharing_attention_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = WeightSharingAttentionExtractor\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.monitor_weights import plot_gating_distribution\n",
        "import os\n",
        "\n",
        "# Plot the results\n",
        "weights_file = f\"./gating_weights/gating_weights_{env}.pkl\"\n",
        "if os.path.exists(weights_file):\n",
        "    plot_gating_distribution(weights_file, output_dir=\"./gating_plots\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Warning: Weights file not found at {weights_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train MOE agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Configure MoE with different exploration settings\n",
        "from utils.feature_extractors import SoftHardMOE\n",
        "\n",
        "f_ext_kwargs = environment_configuration[\"f_ext_kwargs\"]\n",
        "environment_configuration[\"f_ext_name\"] = \"moe_ext\"\n",
        "environment_configuration[\"f_ext_class\"] = SoftHardMOE\n",
        "f_ext_kwargs[\"skills\"] = skills\n",
        "f_ext_kwargs[\"features_dim\"] = 256\n",
        "\n",
        "# Exploration and load balancing parameters\n",
        "f_ext_kwargs[\"min_temperature\"] = 0.1  # Try 0.01, 0.05, 0.1, 0.2\n",
        "f_ext_kwargs[\"temperature_decay\"] = 0.99998    # Try 0.001, 0.01, 0.05\n",
        "\n",
        "\n",
        "policy_kwargs[\"features_extractor_class\"] = environment_configuration[\"f_ext_class\"]\n",
        "policy_kwargs[\"features_extractor_kwargs\"] = f_ext_kwargs\n",
        "\n",
        "train_agent(env, environment_configuration, policy_kwargs, seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.monitor_weights import plot_gating_distribution\n",
        "import os\n",
        "\n",
        "env = \"PongNoFrameskip-v4\"\n",
        "\n",
        "# Plot the results\n",
        "weights_file = f\"./gating_weights/gating_weights_{env}.pkl\"\n",
        "if os.path.exists(weights_file):\n",
        "    plot_gating_distribution(weights_file, output_dir=\"./gating_plots\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Warning: Weights file not found at {weights_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "medium-skill-based-agents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
