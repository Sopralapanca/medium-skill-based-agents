{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def visualize_segmentation(model, data_path, game=None, num_samples=5, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize video object segmentation results similar to Figure 3 in the paper.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained VideoObjectSegmentationModel\n",
    "        data_path: Path to the dataset\n",
    "        game: Specific game to visualize (optional)\n",
    "        num_samples: Number of samples to visualize\n",
    "        save_path: Path to save the figure (optional)\n",
    "    \"\"\"\n",
    "    batch_size = 32\n",
    "    num_frames = 2\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Load data\n",
    "    data = VOSDataset(batch_size, num_frames, data_path, game=game)\n",
    "    inp = data.get_batch(\"train\").to(device)\n",
    "    \n",
    "    # Prepare input (two consecutive frames)\n",
    "    x_input = torch.cat([\n",
    "        torch.unsqueeze(inp[:, 0, :, :], 1), \n",
    "        torch.unsqueeze(inp[:, 1, :, :], 1)\n",
    "    ], 1)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        x_reconstructed = model(x_input)\n",
    "        \n",
    "        # Get masks and compute weighted mask\n",
    "        masks = model.object_masks  # [BS, K, H, W]\n",
    "        translation_masks = model.translation_masks  # [BS, K, 2, H, W]\n",
    "        \n",
    "        # Compute flow magnitude for each object\n",
    "        flow_magnitude = torch.sqrt(\n",
    "            translation_masks[:, :, 0, :, :] ** 2 + \n",
    "            translation_masks[:, :, 1, :, :] ** 2\n",
    "        )  # [BS, K, H, W]\n",
    "        \n",
    "        # Weight masks by their translation magnitude (model confidence)\n",
    "        object_translations = model.obj_trans(\n",
    "            model.relu(model.fc_conv(model.cnn(x_input)))\n",
    "        ).view(-1, model.K, 2)\n",
    "        translation_norms = torch.norm(object_translations, dim=2)  # [BS, K]\n",
    "        \n",
    "        # Weighted sum of masks\n",
    "        weighted_masks = torch.zeros_like(masks[:, 0, :, :])  # [BS, H, W]\n",
    "        for k in range(model.K):\n",
    "            weighted_masks += masks[:, k, :, :] * translation_norms[:, k].unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        # Normalize weighted masks\n",
    "        weighted_masks = weighted_masks / (weighted_masks.max(dim=2, keepdim=True)[0].max(dim=1, keepdim=True)[0] + 1e-8)\n",
    "        \n",
    "        # Find most salient mask for each sample (highest flow regularization penalty)\n",
    "        salient_mask_indices = torch.argmax(\n",
    "            torch.norm(translation_masks, dim=2).sum(dim=2).sum(dim=2), \n",
    "            dim=1\n",
    "        )  # [BS]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(num_samples, 5, figsize=(20, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Create green colormap for overlay\n",
    "    colors_green = [(0, 0, 0, 0), (0, 1, 0, 1)]\n",
    "    n_bins = 256\n",
    "    cmap_green = LinearSegmentedColormap.from_list('green_alpha', colors_green, N=n_bins)\n",
    "    \n",
    "    for i in range(min(num_samples, batch_size)):\n",
    "        # Frame 0 (x0)\n",
    "        frame0 = inp[i, 0, :, :].cpu().numpy()\n",
    "        axes[i, 0].imshow(frame0, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 0].set_title('Frame 0 (x₀)')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Frame 1 (x1)\n",
    "        frame1 = inp[i, 1, :, :].cpu().numpy()\n",
    "        axes[i, 1].imshow(frame1, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 1].set_title('Frame 1 (x₁)')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Most salient mask overlay\n",
    "        salient_idx = salient_mask_indices[i].item()\n",
    "        salient_mask = masks[i, salient_idx, :, :].cpu().numpy()\n",
    "        axes[i, 2].imshow(frame1, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 2].imshow(salient_mask, cmap=cmap_green, alpha=0.6, vmin=0, vmax=1)\n",
    "        axes[i, 2].set_title(f'Most Salient Object (Mask {salient_idx})')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Weighted sum of all masks\n",
    "        weighted_mask = weighted_masks[i].cpu().numpy()\n",
    "        axes[i, 3].imshow(frame1, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 3].imshow(weighted_mask, cmap=cmap_green, alpha=0.6, vmin=0, vmax=1)\n",
    "        axes[i, 3].set_title('All Objects (Weighted Sum)')\n",
    "        axes[i, 3].axis('off')\n",
    "        \n",
    "        # Optical flow visualization\n",
    "        flow = translation_masks[i].sum(dim=0).cpu().numpy()  # [2, H, W]\n",
    "        flow_magnitude_vis = np.sqrt(flow[0]**2 + flow[1]**2)\n",
    "        flow_angle = np.arctan2(flow[0], flow[1])\n",
    "        \n",
    "        # Create HSV image (hue=direction, value=magnitude)\n",
    "        hsv = np.zeros((flow.shape[1], flow.shape[2], 3))\n",
    "        hsv[:, :, 0] = (flow_angle + np.pi) / (2 * np.pi)  # Hue\n",
    "        hsv[:, :, 1] = 1.0  # Saturation\n",
    "        hsv[:, :, 2] = flow_magnitude_vis / (flow_magnitude_vis.max() + 1e-8)  # Value\n",
    "        \n",
    "        from matplotlib.colors import hsv_to_rgb\n",
    "        rgb_flow = hsv_to_rgb(hsv)\n",
    "        \n",
    "        axes[i, 4].imshow(rgb_flow)\n",
    "        axes[i, 4].set_title('Optical Flow')\n",
    "        axes[i, 4].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def visualize_individual_masks(model, data_path, game=None, sample_idx=0, num_masks=10):\n",
    "    \"\"\"\n",
    "    Visualize individual object masks for a single sample.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained VideoObjectSegmentationModel\n",
    "        data_path: Path to the dataset\n",
    "        game: Specific game to visualize (optional)\n",
    "        sample_idx: Index of sample to visualize\n",
    "        num_masks: Number of top masks to display\n",
    "    \"\"\"\n",
    "    batch_size = 32\n",
    "    num_frames = 2\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Load data\n",
    "    data = VOSDataset(batch_size, num_frames, data_path, game=game)\n",
    "    inp = data.get_batch(\"train\").to(device)\n",
    "    \n",
    "    # Prepare input\n",
    "    x_input = torch.cat([\n",
    "        torch.unsqueeze(inp[:, 0, :, :], 1), \n",
    "        torch.unsqueeze(inp[:, 1, :, :], 1)\n",
    "    ], 1)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(x_input)\n",
    "        masks = model.object_masks  # [BS, K, H, W]\n",
    "        translation_masks = model.translation_masks  # [BS, K, 2, H, W]\n",
    "        \n",
    "        # Compute importance of each mask\n",
    "        mask_importance = torch.norm(translation_masks[sample_idx], dim=1).sum(dim=1).sum(dim=1)\n",
    "        top_mask_indices = torch.argsort(mask_importance, descending=True)[:num_masks]\n",
    "    \n",
    "    # Visualize\n",
    "    cols = 5\n",
    "    rows = (num_masks + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3*cols, 3*rows))\n",
    "    axes = axes.flatten() if num_masks > 1 else [axes]\n",
    "    \n",
    "    frame = inp[sample_idx, 1, :, :].cpu().numpy()\n",
    "    \n",
    "    for i, mask_idx in enumerate(top_mask_indices):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "        mask = masks[sample_idx, mask_idx, :, :].cpu().numpy()\n",
    "        importance = mask_importance[mask_idx].item()\n",
    "        \n",
    "        axes[i].imshow(frame, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i].imshow(mask, cmap='Greens', alpha=0.6, vmin=0, vmax=1)\n",
    "        axes[i].set_title(f'Mask {mask_idx.item()} (imp: {importance:.2f})')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(top_mask_indices), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
